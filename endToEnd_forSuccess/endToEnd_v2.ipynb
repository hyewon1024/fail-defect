{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a5eee0",
   "metadata": {},
   "source": [
    "#성공 데이터 전처리\n",
    "4가지 전처리 과정이 포함됩니다.\n",
    "\n",
    "resent18<br>\n",
    "resent18 + robotdata<br>\n",
    "resnet18 -> pca<br>\n",
    "resnet18 -> pca + robotdata<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e12e5b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode    1] success_episode1_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode1_steps70', array shape=(70, 1536)\n",
      "[Episode    2] success_episode2_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode2_steps70', array shape=(70, 1536)\n",
      "[Episode    3] success_episode3_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode3_steps70', array shape=(70, 1536)\n",
      "[Episode    4] success_episode4_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode4_steps70', array shape=(70, 1536)\n",
      "[Episode    5] success_episode5_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode5_steps70', array shape=(70, 1536)\n",
      "[Episode    6] success_episode6_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode6_steps70', array shape=(70, 1536)\n",
      "[Episode    7] success_episode7_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode7_steps70', array shape=(70, 1536)\n",
      "[Episode    8] success_episode8_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode8_steps70', array shape=(70, 1536)\n",
      "[Episode    9] success_episode9_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode9_steps70', array shape=(70, 1536)\n",
      "[Episode   10] success_episode10_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode10_steps70', array shape=(70, 1536)\n",
      "[Episode   11] success_episode11_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode11_steps70', array shape=(70, 1536)\n",
      "[Episode   12] success_episode12_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode12_steps70', array shape=(70, 1536)\n",
      "[Episode   13] success_episode13_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode13_steps70', array shape=(70, 1536)\n",
      "[Episode   14] success_episode14_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode14_steps70', array shape=(70, 1536)\n",
      "[Episode   15] success_episode15_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode15_steps70', array shape=(70, 1536)\n",
      "[Episode   16] success_episode16_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode16_steps70', array shape=(70, 1536)\n",
      "[Episode   17] success_episode17_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode17_steps70', array shape=(70, 1536)\n",
      "[Episode   18] success_episode18_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode18_steps70', array shape=(70, 1536)\n",
      "[Episode   19] success_episode19_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode19_steps70', array shape=(70, 1536)\n",
      "[Episode   20] success_episode20_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode20_steps70', array shape=(70, 1536)\n",
      "[Episode   21] success_episode21_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode21_steps70', array shape=(70, 1536)\n",
      "[Episode   22] success_episode22_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode22_steps70', array shape=(70, 1536)\n",
      "[Episode   23] success_episode23_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode23_steps70', array shape=(70, 1536)\n",
      "[Episode   24] success_episode24_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode24_steps70', array shape=(70, 1536)\n",
      "[Episode   25] success_episode25_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode25_steps70', array shape=(70, 1536)\n",
      "[Episode   26] success_episode26_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode26_steps70', array shape=(70, 1536)\n",
      "[Episode   27] success_episode27_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode27_steps70', array shape=(70, 1536)\n",
      "[Episode   28] success_episode28_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode28_steps70', array shape=(70, 1536)\n",
      "[Episode   29] success_episode29_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode29_steps70', array shape=(70, 1536)\n",
      "[Episode   30] success_episode30_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode30_steps70', array shape=(70, 1536)\n",
      "[Episode   31] success_episode31_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode31_steps70', array shape=(70, 1536)\n",
      "[Episode   32] success_episode32_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode32_steps70', array shape=(70, 1536)\n",
      "[Episode   33] success_episode33_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode33_steps70', array shape=(70, 1536)\n",
      "[Episode   34] success_episode34_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode34_steps70', array shape=(70, 1536)\n",
      "[Episode   35] success_episode35_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode35_steps70', array shape=(70, 1536)\n",
      "[Episode   36] success_episode36_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode36_steps70', array shape=(70, 1536)\n",
      "[Episode   37] success_episode37_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode37_steps70', array shape=(70, 1536)\n",
      "[Episode   38] success_episode38_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode38_steps70', array shape=(70, 1536)\n",
      "[Episode   39] success_episode39_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode39_steps70', array shape=(70, 1536)\n",
      "[Episode   40] success_episode40_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode40_steps70', array shape=(70, 1536)\n",
      "[Episode   41] success_episode41_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode41_steps70', array shape=(70, 1536)\n",
      "[Episode   42] success_episode42_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode42_steps70', array shape=(70, 1536)\n",
      "[Episode   43] success_episode43_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode43_steps70', array shape=(70, 1536)\n",
      "[Episode   44] success_episode44_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode44_steps70', array shape=(70, 1536)\n",
      "[Episode   45] success_episode45_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode45_steps70', array shape=(70, 1536)\n",
      "[Episode   46] success_episode46_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode46_steps70', array shape=(70, 1536)\n",
      "[Episode   47] success_episode47_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode47_steps70', array shape=(70, 1536)\n",
      "[Episode   48] success_episode48_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode48_steps70', array shape=(70, 1536)\n",
      "[Episode   49] success_episode49_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode49_steps70', array shape=(70, 1536)\n",
      "[Episode   50] success_episode50_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode50_steps70', array shape=(70, 1536)\n",
      "[Episode   51] success_episode51_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode51_steps70', array shape=(70, 1536)\n",
      "[Episode   52] success_episode52_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode52_steps70', array shape=(70, 1536)\n",
      "[Episode   53] success_episode53_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode53_steps70', array shape=(70, 1536)\n",
      "[Episode   54] success_episode54_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode54_steps70', array shape=(70, 1536)\n",
      "[Episode   55] success_episode55_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode55_steps70', array shape=(70, 1536)\n",
      "[Episode   56] success_episode56_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode56_steps70', array shape=(70, 1536)\n",
      "[Episode   57] success_episode57_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode57_steps70', array shape=(70, 1536)\n",
      "[Episode   58] success_episode58_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode58_steps70', array shape=(70, 1536)\n",
      "[Episode   59] success_episode59_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode59_steps70', array shape=(70, 1536)\n",
      "[Episode   60] success_episode60_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode60_steps70', array shape=(70, 1536)\n",
      "[Episode   61] success_episode61_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode61_steps70', array shape=(70, 1536)\n",
      "[Episode   62] success_episode62_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode62_steps70', array shape=(70, 1536)\n",
      "[Episode   63] success_episode63_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode63_steps70', array shape=(70, 1536)\n",
      "[Episode   64] success_episode64_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode64_steps70', array shape=(70, 1536)\n",
      "[Episode   65] success_episode65_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode65_steps70', array shape=(70, 1536)\n",
      "[Episode   66] success_episode66_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode66_steps70', array shape=(70, 1536)\n",
      "[Episode   67] success_episode67_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode67_steps70', array shape=(70, 1536)\n",
      "[Episode   68] success_episode68_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode68_steps70', array shape=(70, 1536)\n",
      "[Episode   69] success_episode69_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode69_steps70', array shape=(70, 1536)\n",
      "[Episode   70] success_episode70_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode70_steps70', array shape=(70, 1536)\n",
      "[Episode   71] success_episode71_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode71_steps70', array shape=(70, 1536)\n",
      "[Episode   72] success_episode72_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode72_steps70', array shape=(70, 1536)\n",
      "[Episode   73] success_episode73_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode73_steps70', array shape=(70, 1536)\n",
      "[Episode   74] success_episode74_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode74_steps70', array shape=(70, 1536)\n",
      "[Episode   75] success_episode75_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode75_steps70', array shape=(70, 1536)\n",
      "\n",
      "Saved: dataset_natural_fail/fail_data_resnet18_robotX.pkl\n",
      "Total episodes: 75\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "apply resent18 (for success)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"success_episode{episode_number}_steps{episode_length//5+1}\":\n",
    "        [episode_length//5+1, 512*3] #front, top, wrist\n",
    "    }\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "os.makedirs(\"dataset_natural_fail\", exist_ok=True)\n",
    "\n",
    "# ====== 설정 ======\n",
    "ROOT_DIR = \"/AILAB-summer-school-2025/fail_during_success_data/\"   # 입력 루트\n",
    "OUT_PATH = \"dataset_natural_fail/fail_data_resnet18_robotX.pkl\"                    # 출력 파일\n",
    "VIEWS = (\"front\", \"top\", \"wrist\")                         # 처리할 뷰\n",
    "\n",
    "# 이미지 전처리 (요청 그대로)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std= [0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# 에피소드 폴더명: success_episode{num}_steps{episode_length}\n",
    "EP_DIR_RE = re.compile(r\"^success_episode(\\d+)_steps(\\d+)$\")\n",
    "\n",
    "\n",
    "def parse_episode_dirname(name: str) -> Tuple[int, int]:\n",
    "    m = EP_DIR_RE.match(name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Invalid episode dir name: {name}\")\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "\n",
    "def list_episode_dirs(root: str) -> List[Tuple[int, int, str, str]]:\n",
    "    \"\"\"(ep_num, ep_len, abs_path, dir_name) 를 ep_num 오름차순으로 반환\"\"\"\n",
    "    eps = []\n",
    "    for name in os.listdir(root):\n",
    "        p = os.path.join(root, name)\n",
    "        if not os.path.isdir(p):\n",
    "            continue\n",
    "        if EP_DIR_RE.match(name):\n",
    "            ep_num, ep_len = parse_episode_dirname(name)\n",
    "            eps.append((ep_num, ep_len, p, name))\n",
    "    eps.sort(key=lambda x: x[0])\n",
    "    return eps\n",
    "\n",
    "\n",
    "def expected_steps(ep_len: int) -> List[int]:\n",
    "    \"\"\"0부터 (ep_len-1)까지 5 간격 스텝 (예: ep_len=320 -> [0,5,...,315], 총 64개)\"\"\"\n",
    "    return list(range(0, ep_len, 5))\n",
    "\n",
    "\n",
    "def img_path(ep_path: str, view: str, step: int) -> str:\n",
    "    \"\"\"뷰/스텝에 해당하는 이미지 경로\"\"\"\n",
    "    return os.path.join(ep_path, f\"{view}_view\", f\"{view}_view_{step}.png\")\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def extract_feature(model: nn.Module, path: str, device: torch.device) -> np.ndarray:\n",
    "    with Image.open(path).convert(\"RGB\") as img:\n",
    "        x = transform(img).unsqueeze(0).to(device)\n",
    "        f = model(x).squeeze(0).detach().cpu().numpy().astype(np.float32)  # (512,)\n",
    "    return f\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 모델 준비 (ResNet18 + ImageNet 가중치, FC 제거 → 512차원)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Identity()\n",
    "    model.eval().to(device)\n",
    "\n",
    "    # 에피소드 스캔\n",
    "    episodes = list_episode_dirs(ROOT_DIR)\n",
    "    if not episodes:\n",
    "        raise RuntimeError(f\"No valid episode directories found under '{ROOT_DIR}'\")\n",
    "\n",
    "    data: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    for ep_num, ep_len, ep_path, ep_name in episodes:\n",
    "        steps = expected_steps(ep_len)                 # 길이 = ep_len // 5\n",
    "        print(f\"[Episode {ep_num:>4}] {ep_name} -> steps expected: {len(steps)} (0..{ep_len-1} by 5)\")\n",
    "\n",
    "        # 파일 존재 검증(세 뷰 모두)\n",
    "        missing = []\n",
    "        for s in steps:\n",
    "            for v in VIEWS:\n",
    "                p = img_path(ep_path, v, s)\n",
    "                if not os.path.isfile(p):\n",
    "                    missing.append(p)\n",
    "        if missing:\n",
    "            # 어떤 에피소드에서든 필수 스텝이 비어있으면 바로 알려주고 중단\n",
    "            preview = \"\\n\".join(missing[:20])\n",
    "            tail = \"\" if len(missing) <= 20 else f\"\\n... (+{len(missing)-20} more)\"\n",
    "            raise FileNotFoundError(\n",
    "                f\"[{ep_name}] Missing required image files:\\n{preview}{tail}\"\n",
    "            )\n",
    "\n",
    "        # 특징 추출\n",
    "        episode_feats = []\n",
    "        for s in steps:\n",
    "            paths = [img_path(ep_path, v, s) for v in VIEWS]\n",
    "            feats = [extract_feature(model, p, device) for p in paths]  # 3 x (512,)\n",
    "            merged = np.concatenate(feats, axis=0)  # (1536,)\n",
    "            episode_feats.append(merged)\n",
    "            #print(f\"    - step {s:>4}  OK\")\n",
    "\n",
    "        arr = np.stack(episode_feats, axis=0)  # (T, 1536), T = ep_len // 5\n",
    "        key = f\"success_episode{ep_num}_steps{len(steps)}\"\n",
    "        data[key] = arr\n",
    "        print(f\"  -> Added episode: key='{key}', array shape={arr.shape}\")\n",
    "\n",
    "    # 저장\n",
    "    with open(OUT_PATH, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"\\nSaved: {OUT_PATH}\")\n",
    "    print(f\"Total episodes: {len(data)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85a0a0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode    1] success_episode1_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode1_steps70', array shape=(70, 1543)\n",
      "[Episode    2] success_episode2_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode2_steps70', array shape=(70, 1543)\n",
      "[Episode    3] success_episode3_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode3_steps70', array shape=(70, 1543)\n",
      "[Episode    4] success_episode4_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode4_steps70', array shape=(70, 1543)\n",
      "[Episode    5] success_episode5_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode5_steps70', array shape=(70, 1543)\n",
      "[Episode    6] success_episode6_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode6_steps70', array shape=(70, 1543)\n",
      "[Episode    7] success_episode7_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode7_steps70', array shape=(70, 1543)\n",
      "[Episode    8] success_episode8_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode8_steps70', array shape=(70, 1543)\n",
      "[Episode    9] success_episode9_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode9_steps70', array shape=(70, 1543)\n",
      "[Episode   10] success_episode10_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode10_steps70', array shape=(70, 1543)\n",
      "[Episode   11] success_episode11_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode11_steps70', array shape=(70, 1543)\n",
      "[Episode   12] success_episode12_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode12_steps70', array shape=(70, 1543)\n",
      "[Episode   13] success_episode13_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode13_steps70', array shape=(70, 1543)\n",
      "[Episode   14] success_episode14_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode14_steps70', array shape=(70, 1543)\n",
      "[Episode   15] success_episode15_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode15_steps70', array shape=(70, 1543)\n",
      "[Episode   16] success_episode16_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode16_steps70', array shape=(70, 1543)\n",
      "[Episode   17] success_episode17_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode17_steps70', array shape=(70, 1543)\n",
      "[Episode   18] success_episode18_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode18_steps70', array shape=(70, 1543)\n",
      "[Episode   19] success_episode19_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode19_steps70', array shape=(70, 1543)\n",
      "[Episode   20] success_episode20_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode20_steps70', array shape=(70, 1543)\n",
      "[Episode   21] success_episode21_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode21_steps70', array shape=(70, 1543)\n",
      "[Episode   22] success_episode22_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode22_steps70', array shape=(70, 1543)\n",
      "[Episode   23] success_episode23_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode23_steps70', array shape=(70, 1543)\n",
      "[Episode   24] success_episode24_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode24_steps70', array shape=(70, 1543)\n",
      "[Episode   25] success_episode25_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode25_steps70', array shape=(70, 1543)\n",
      "[Episode   26] success_episode26_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode26_steps70', array shape=(70, 1543)\n",
      "[Episode   27] success_episode27_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode27_steps70', array shape=(70, 1543)\n",
      "[Episode   28] success_episode28_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode28_steps70', array shape=(70, 1543)\n",
      "[Episode   29] success_episode29_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode29_steps70', array shape=(70, 1543)\n",
      "[Episode   30] success_episode30_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode30_steps70', array shape=(70, 1543)\n",
      "[Episode   31] success_episode31_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode31_steps70', array shape=(70, 1543)\n",
      "[Episode   32] success_episode32_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode32_steps70', array shape=(70, 1543)\n",
      "[Episode   33] success_episode33_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode33_steps70', array shape=(70, 1543)\n",
      "[Episode   34] success_episode34_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode34_steps70', array shape=(70, 1543)\n",
      "[Episode   35] success_episode35_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode35_steps70', array shape=(70, 1543)\n",
      "[Episode   36] success_episode36_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode36_steps70', array shape=(70, 1543)\n",
      "[Episode   37] success_episode37_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode37_steps70', array shape=(70, 1543)\n",
      "[Episode   38] success_episode38_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode38_steps70', array shape=(70, 1543)\n",
      "[Episode   39] success_episode39_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode39_steps70', array shape=(70, 1543)\n",
      "[Episode   40] success_episode40_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode40_steps70', array shape=(70, 1543)\n",
      "[Episode   41] success_episode41_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode41_steps70', array shape=(70, 1543)\n",
      "[Episode   42] success_episode42_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode42_steps70', array shape=(70, 1543)\n",
      "[Episode   43] success_episode43_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode43_steps70', array shape=(70, 1543)\n",
      "[Episode   44] success_episode44_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode44_steps70', array shape=(70, 1543)\n",
      "[Episode   45] success_episode45_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode45_steps70', array shape=(70, 1543)\n",
      "[Episode   46] success_episode46_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode46_steps70', array shape=(70, 1543)\n",
      "[Episode   47] success_episode47_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode47_steps70', array shape=(70, 1543)\n",
      "[Episode   48] success_episode48_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode48_steps70', array shape=(70, 1543)\n",
      "[Episode   49] success_episode49_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode49_steps70', array shape=(70, 1543)\n",
      "[Episode   50] success_episode50_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode50_steps70', array shape=(70, 1543)\n",
      "[Episode   51] success_episode51_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode51_steps70', array shape=(70, 1543)\n",
      "[Episode   52] success_episode52_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode52_steps70', array shape=(70, 1543)\n",
      "[Episode   53] success_episode53_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode53_steps70', array shape=(70, 1543)\n",
      "[Episode   54] success_episode54_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode54_steps70', array shape=(70, 1543)\n",
      "[Episode   55] success_episode55_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode55_steps70', array shape=(70, 1543)\n",
      "[Episode   56] success_episode56_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode56_steps70', array shape=(70, 1543)\n",
      "[Episode   57] success_episode57_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode57_steps70', array shape=(70, 1543)\n",
      "[Episode   58] success_episode58_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode58_steps70', array shape=(70, 1543)\n",
      "[Episode   59] success_episode59_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode59_steps70', array shape=(70, 1543)\n",
      "[Episode   60] success_episode60_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode60_steps70', array shape=(70, 1543)\n",
      "[Episode   61] success_episode61_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode61_steps70', array shape=(70, 1543)\n",
      "[Episode   62] success_episode62_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode62_steps70', array shape=(70, 1543)\n",
      "[Episode   63] success_episode63_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode63_steps70', array shape=(70, 1543)\n",
      "[Episode   64] success_episode64_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode64_steps70', array shape=(70, 1543)\n",
      "[Episode   65] success_episode65_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode65_steps70', array shape=(70, 1543)\n",
      "[Episode   66] success_episode66_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode66_steps70', array shape=(70, 1543)\n",
      "[Episode   67] success_episode67_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode67_steps70', array shape=(70, 1543)\n",
      "[Episode   68] success_episode68_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode68_steps70', array shape=(70, 1543)\n",
      "[Episode   69] success_episode69_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode69_steps70', array shape=(70, 1543)\n",
      "[Episode   70] success_episode70_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode70_steps70', array shape=(70, 1543)\n",
      "[Episode   71] success_episode71_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode71_steps70', array shape=(70, 1543)\n",
      "[Episode   72] success_episode72_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode72_steps70', array shape=(70, 1543)\n",
      "[Episode   73] success_episode73_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode73_steps70', array shape=(70, 1543)\n",
      "[Episode   74] success_episode74_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode74_steps70', array shape=(70, 1543)\n",
      "[Episode   75] success_episode75_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode75_steps70', array shape=(70, 1543)\n",
      "\n",
      "Saved: dataset_natural_fail/fail_data_resnet18_robotO.pkl\n",
      "Total episodes: 75\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "apply resent18 + robotdata (for success)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"success_episode{episode_number}_steps{episode_length//5+1}\":\n",
    "        [episode_length//5+1, 512*3+7] #front, top, wrist, robot_data\n",
    "    }\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from typing import Dict, Tuple, List, Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# ====== 설정 ======\n",
    "ROOT_DIR = \"/AILAB-summer-school-2025/fail_during_success_data/\"   # 입력 루트\n",
    "OUT_PATH = \"dataset_natural_fail/fail_data_resnet18_robotO.pkl\"                    # 출력 파일\n",
    "VIEWS = (\"front\", \"top\", \"wrist\")                         # 처리할 뷰\n",
    "\n",
    "# 이미지 전처리 (요청 그대로)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std= [0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# 에피소드 폴더명: success_episode{num}_steps{episode_length}\n",
    "EP_DIR_RE = re.compile(r\"^success_episode(\\d+)_steps(\\d+)$\")\n",
    "\n",
    "\n",
    "def parse_episode_dirname(name: str) -> Tuple[int, int]:\n",
    "    m = EP_DIR_RE.match(name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Invalid episode dir name: {name}\")\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "\n",
    "def list_episode_dirs(root: str) -> List[Tuple[int, int, str, str]]:\n",
    "    \"\"\"(ep_num, ep_len, abs_path, dir_name) 를 ep_num 오름차순으로 반환\"\"\"\n",
    "    eps = []\n",
    "    for name in os.listdir(root):\n",
    "        p = os.path.join(root, name)\n",
    "        if not os.path.isdir(p):\n",
    "            continue\n",
    "        if EP_DIR_RE.match(name):\n",
    "            ep_num, ep_len = parse_episode_dirname(name)\n",
    "            eps.append((ep_num, ep_len, p, name))\n",
    "    eps.sort(key=lambda x: x[0])\n",
    "    return eps\n",
    "\n",
    "\n",
    "def expected_steps(ep_len: int) -> List[int]:\n",
    "    \"\"\"0부터 (ep_len-1)까지 5 간격 스텝 (예: ep_len=320 -> [0,5,...,315], 총 64개)\"\"\"\n",
    "    return list(range(0, ep_len, 5))\n",
    "\n",
    "\n",
    "def img_path(ep_path: str, view: str, step: int) -> str:\n",
    "    \"\"\"뷰/스텝에 해당하는 이미지 경로\"\"\"\n",
    "    return os.path.join(ep_path, f\"{view}_view\", f\"{view}_view_{step}.png\")\n",
    "\n",
    "\n",
    "def coerce_2d_float(arr, dim2: int) -> np.ndarray:\n",
    "    \"\"\"리스트/obj-array도 (T,dim2) float32로 강제.\"\"\"\n",
    "    if isinstance(arr, np.ndarray) and arr.dtype != object:\n",
    "        out = arr\n",
    "    else:\n",
    "        out = np.asarray([np.asarray(x).reshape(-1) for x in arr], dtype=np.float32)\n",
    "    if out.ndim != 2 or out.shape[1] != dim2:\n",
    "        raise ValueError(f\"Expected shape (T,{dim2}) but got {out.shape}\")\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def extract_feature(model: nn.Module, path: str, device: torch.device) -> np.ndarray:\n",
    "    with Image.open(path).convert(\"RGB\") as img:\n",
    "        x = transform(img).unsqueeze(0).to(device)\n",
    "        f = model(x).squeeze(0).detach().cpu().numpy().astype(np.float32)  # (512,)\n",
    "    return f\n",
    "\n",
    "\n",
    "def pick_pose_indexer(ep_len: int, steps: List[int], T_pose: int) -> Callable[[int, int], int]:\n",
    "    \"\"\"\n",
    "    EE_pose 인덱싱 전략을 선택해 indexer(i, s)를 반환.\n",
    "    - 가장 흔한 케이스: T_pose == len(steps)  -> i로 인덱싱\n",
    "    - 프레임 전부 저장: T_pose >= ep_len      -> s로 인덱싱\n",
    "    - 포함 케이스: T_pose == len(steps)+1     -> i로 인덱싱(마지막 한 칸 여유)\n",
    "    - 다른 경우는 모호 → 에러\n",
    "    \"\"\"\n",
    "    T_steps = len(steps)\n",
    "    if T_pose == T_steps or T_pose == T_steps + 1:\n",
    "        return lambda i, s: i\n",
    "    if T_pose >= ep_len:\n",
    "        return lambda i, s: s\n",
    "    # 보수적으로 한 번 더 허용: ep_len//5 == T_pose (동일 의미)\n",
    "    if T_pose == (ep_len // 5):\n",
    "        return lambda i, s: i\n",
    "    raise ValueError(\n",
    "        f\"Cannot map EE_pose length {T_pose} to steps={T_steps} (episode_length={ep_len}). \"\n",
    "        f\"Expected one of {{T_steps, T_steps+1, >= ep_len}}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 모델 준비 (ResNet18 + ImageNet 가중치, FC 제거 → 512차원)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Identity()\n",
    "    model.eval().to(device)\n",
    "\n",
    "    # 에피소드 스캔\n",
    "    episodes = list_episode_dirs(ROOT_DIR)\n",
    "    if not episodes:\n",
    "        raise RuntimeError(f\"No valid episode directories found under '{ROOT_DIR}'\")\n",
    "\n",
    "    data: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    for ep_num, ep_len, ep_path, ep_name in episodes:\n",
    "        steps = expected_steps(ep_len)  # 길이 = ep_len // 5\n",
    "        print(f\"[Episode {ep_num:>4}] {ep_name} -> steps expected: {len(steps)} (0..{ep_len-1} by 5)\")\n",
    "\n",
    "        # robot_state.npz 로드 및 EE_pose 확보\n",
    "        state_path = os.path.join(ep_path, \"robot_state.npz\")\n",
    "        if not os.path.isfile(state_path):\n",
    "            raise FileNotFoundError(f\"[{ep_name}] robot_state.npz not found: {state_path}\")\n",
    "        state = np.load(state_path, allow_pickle=True)\n",
    "        if \"EE_pose\" not in state:\n",
    "            raise KeyError(f\"[{ep_name}] 'EE_pose' key not found in {state_path}\")\n",
    "        ee_pose = coerce_2d_float(state[\"EE_pose\"], dim2=7)  # (T_pose, 7)\n",
    "        T_pose = ee_pose.shape[0]\n",
    "\n",
    "        # 이미지 파일 존재 검증(세 뷰 모두)\n",
    "        missing = []\n",
    "        for s in steps:\n",
    "            for v in VIEWS:\n",
    "                p = img_path(ep_path, v, s)\n",
    "                if not os.path.isfile(p):\n",
    "                    missing.append(p)\n",
    "        if missing:\n",
    "            preview = \"\\n\".join(missing[:20])\n",
    "            tail = \"\" if len(missing) <= 20 else f\"\\n... (+{len(missing)-20} more)\"\n",
    "            raise FileNotFoundError(\n",
    "                f\"[{ep_name}] Missing required image files:\\n{preview}{tail}\"\n",
    "            )\n",
    "\n",
    "        # EE_pose 인덱싱 모드 선택\n",
    "        indexer = pick_pose_indexer(ep_len, steps, T_pose)\n",
    "\n",
    "        # 특징 추출 + EE_pose concat\n",
    "        episode_feats = []\n",
    "        for i, s in enumerate(steps):\n",
    "            paths = [img_path(ep_path, v, s) for v in VIEWS]\n",
    "            feats = [extract_feature(model, p, device) for p in paths]  # 3 x (512,)\n",
    "            pose = ee_pose[indexer(i, s)].astype(np.float32, copy=False) # (7,)\n",
    "            merged = np.concatenate(feats + [pose], axis=0)              # (1536 + 7 = 1543,)\n",
    "            episode_feats.append(merged)\n",
    "            #print(f\"    - step {s:>4}  OK\")\n",
    "\n",
    "        arr = np.stack(episode_feats, axis=0)  # (T, 1543), T = ep_len // 5\n",
    "        key = f\"success_episode{ep_num}_steps{len(steps)}\"\n",
    "        data[key] = arr\n",
    "        print(f\"  -> Added episode: key='{key}', array shape={arr.shape}\")\n",
    "\n",
    "    # 저장\n",
    "    with open(OUT_PATH, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"\\nSaved: {OUT_PATH}\")\n",
    "    print(f\"Total episodes: {len(data)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc1578d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Added episode: key='success_episode53_steps70', array shape=(70, 192)\n",
      "[Episode   54] success_episode54_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode54_steps70', array shape=(70, 192)\n",
      "[Episode   55] success_episode55_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode55_steps70', array shape=(70, 192)\n",
      "[Episode   56] success_episode56_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode56_steps70', array shape=(70, 192)\n",
      "[Episode   57] success_episode57_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode57_steps70', array shape=(70, 192)\n",
      "[Episode   58] success_episode58_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode58_steps70', array shape=(70, 192)\n",
      "[Episode   59] success_episode59_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode59_steps70', array shape=(70, 192)\n",
      "[Episode   60] success_episode60_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode60_steps70', array shape=(70, 192)\n",
      "[Episode   61] success_episode61_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode61_steps70', array shape=(70, 192)\n",
      "[Episode   62] success_episode62_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode62_steps70', array shape=(70, 192)\n",
      "[Episode   63] success_episode63_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode63_steps70', array shape=(70, 192)\n",
      "[Episode   64] success_episode64_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode64_steps70', array shape=(70, 192)\n",
      "[Episode   65] success_episode65_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode65_steps70', array shape=(70, 192)\n",
      "[Episode   66] success_episode66_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode66_steps70', array shape=(70, 192)\n",
      "[Episode   67] success_episode67_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode67_steps70', array shape=(70, 192)\n",
      "[Episode   68] success_episode68_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode68_steps70', array shape=(70, 192)\n",
      "[Episode   69] success_episode69_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode69_steps70', array shape=(70, 192)\n",
      "[Episode   70] success_episode70_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode70_steps70', array shape=(70, 192)\n",
      "[Episode   71] success_episode71_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode71_steps70', array shape=(70, 192)\n",
      "[Episode   72] success_episode72_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode72_steps70', array shape=(70, 192)\n",
      "[Episode   73] success_episode73_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode73_steps70', array shape=(70, 192)\n",
      "[Episode   74] success_episode74_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode74_steps70', array shape=(70, 192)\n",
      "[Episode   75] success_episode75_steps349 -> steps expected: 70 (0..348 by 5)\n",
      "  -> Added episode: key='success_episode75_steps70', array shape=(70, 192)\n",
      "\n",
      "Saved: dataset_natural_fail/fail_data_resnet18_pca_robotX.pkl\n",
      "Total episodes: 75\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "apply resnet18 -> pca (for success)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"success_episode{episode_number}_steps{episode_length//5+1}\":\n",
    "        [episode_length//5+1, 64*3] #front, top, wrist\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# ====== 설정 ======\n",
    "ROOT_DIR = \"/AILAB-summer-school-2025/fail_during_success_data\"   # 입력 루트\n",
    "OUT_PATH = \"dataset_natural_fail/fail_data_resnet18_pca_robotX.pkl\"                # 출력 파일 (PCA 버전으로 구분)\n",
    "VIEWS = (\"front\", \"top\", \"wrist\")                         # 처리할 뷰\n",
    "\n",
    "# 이미지 전처리 (요청 그대로)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std= [0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# 에피소드 폴더명: success_episode{num}_steps{episode_length}\n",
    "EP_DIR_RE = re.compile(r\"^success_episode(\\d+)_steps(\\d+)$\")\n",
    "\n",
    "def parse_episode_dirname(name: str) -> Tuple[int, int]:\n",
    "    m = EP_DIR_RE.match(name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Invalid episode dir name: {name}\")\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def list_episode_dirs(root: str) -> List[Tuple[int, int, str, str]]:\n",
    "    \"\"\"(ep_num, ep_len, abs_path, dir_name) 를 ep_num 오름차순으로 반환\"\"\"\n",
    "    eps = []\n",
    "    for name in os.listdir(root):\n",
    "        p = os.path.join(root, name)\n",
    "        if not os.path.isdir(p):\n",
    "            continue\n",
    "        if EP_DIR_RE.match(name):\n",
    "            ep_num, ep_len = parse_episode_dirname(name)\n",
    "            eps.append((ep_num, ep_len, p, name))\n",
    "    eps.sort(key=lambda x: x[0])\n",
    "    return eps\n",
    "\n",
    "def expected_steps(ep_len: int) -> List[int]:\n",
    "    \"\"\"0부터 (ep_len-1)까지 5 간격 스텝 (예: ep_len=320 -> [0,5,...,315], 총 64개)\"\"\"\n",
    "    return list(range(0, ep_len, 5))\n",
    "\n",
    "def img_path(ep_path: str, view: str, step: int) -> str:\n",
    "    return os.path.join(ep_path, f\"{view}_view\", f\"{view}_view_{step}.png\")\n",
    "\n",
    "def get_sorted_image_paths(ep_path: str, view: str, steps: List[int]) -> List[str]:\n",
    "    \"\"\"요구 스텝 순서대로 이미지 경로 생성 & 존재 확인\"\"\"\n",
    "    paths = []\n",
    "    missing = []\n",
    "    for s in steps:\n",
    "        p = img_path(ep_path, view, s)\n",
    "        if os.path.isfile(p):\n",
    "            paths.append(p)\n",
    "        else:\n",
    "            missing.append(p)\n",
    "    if missing:\n",
    "        preview = \"\\n\".join(missing[:20])\n",
    "        tail = \"\" if len(missing) <= 20 else f\"\\n... (+{len(missing)-20} more)\"\n",
    "        raise FileNotFoundError(f\"[{os.path.basename(ep_path)}] Missing {view} images:\\n{preview}{tail}\")\n",
    "    return paths\n",
    "\n",
    "def load_pca_model(view: str):\n",
    "    pca_path = f\"model/model_pca_{view}_view.pkl\"\n",
    "    if not os.path.isfile(pca_path):\n",
    "        raise FileNotFoundError(f\"PCA model not found: {pca_path}\")\n",
    "    with open(pca_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def extract_resnet_feature(model: nn.Module, img_path: str, device: torch.device) -> np.ndarray:\n",
    "    with Image.open(img_path).convert(\"RGB\") as img:\n",
    "        x = transform(img).unsqueeze(0).to(device)\n",
    "        f = model(x).squeeze(0).detach().cpu().numpy().astype(np.float32)  # (512,)\n",
    "    return f\n",
    "\n",
    "def main():\n",
    "    # 모델 준비 (ResNet18 + ImageNet 가중치, FC 제거 → 512차원)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Identity()\n",
    "    model.eval().to(device)\n",
    "\n",
    "    # PCA 모델 미리 로드\n",
    "    pca_models: Dict[str, object] = {v: load_pca_model(v) for v in VIEWS}\n",
    "\n",
    "    # 에피소드 스캔\n",
    "    episodes = list_episode_dirs(ROOT_DIR)\n",
    "    if not episodes:\n",
    "        raise RuntimeError(f\"No valid episode directories found under '{ROOT_DIR}'\")\n",
    "\n",
    "    data: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    for ep_num, ep_len, ep_path, ep_name in episodes:\n",
    "        steps = expected_steps(ep_len)  # 길이 = ep_len // 5\n",
    "        print(f\"[Episode {ep_num:>4}] {ep_name} -> steps expected: {len(steps)} (0..{ep_len-1} by 5)\")\n",
    "\n",
    "        # 뷰별 이미지 리스트 수집(존재 검증 포함)\n",
    "        img_lists: Dict[str, List[str]] = {}\n",
    "        for v in VIEWS:\n",
    "            img_lists[v] = get_sorted_image_paths(ep_path, v, steps)\n",
    "\n",
    "        # 뷰별 ResNet(512) → PCA(64)\n",
    "        latents_64 = []\n",
    "        for v in VIEWS:\n",
    "            paths = img_lists[v]\n",
    "            feats512 = []\n",
    "            for p in paths:\n",
    "                f512 = extract_resnet_feature(model, p, device)  # (512,)\n",
    "                feats512.append(f512)\n",
    "            feats512 = np.stack(feats512, axis=0)               # (T,512)\n",
    "            feats64  = pca_models[v].transform(feats512).astype(np.float32, copy=False)  # (T,64)\n",
    "            latents_64.append(feats64)\n",
    "\n",
    "        # 세 뷰 concat → (T, 64*3 = 192)\n",
    "        arr = np.concatenate(latents_64, axis=1)  # (T, 192)\n",
    "        key = f\"success_episode{ep_num}_steps{len(steps)}\"\n",
    "        data[key] = arr\n",
    "        print(f\"  -> Added episode: key='{key}', array shape={arr.shape}\")\n",
    "\n",
    "    # 저장\n",
    "    with open(OUT_PATH, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"\\nSaved: {OUT_PATH}\")\n",
    "    print(f\"Total episodes: {len(data)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd919076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[success_episode1_steps70] shape: (70, 199)\n",
      "[success_episode2_steps70] shape: (70, 199)\n",
      "[success_episode3_steps70] shape: (70, 199)\n",
      "[success_episode4_steps70] shape: (70, 199)\n",
      "[success_episode5_steps70] shape: (70, 199)\n",
      "[success_episode6_steps70] shape: (70, 199)\n",
      "[success_episode7_steps70] shape: (70, 199)\n",
      "[success_episode8_steps70] shape: (70, 199)\n",
      "[success_episode9_steps70] shape: (70, 199)\n",
      "[success_episode10_steps70] shape: (70, 199)\n",
      "[success_episode11_steps70] shape: (70, 199)\n",
      "[success_episode12_steps70] shape: (70, 199)\n",
      "[success_episode13_steps70] shape: (70, 199)\n",
      "[success_episode14_steps70] shape: (70, 199)\n",
      "[success_episode15_steps70] shape: (70, 199)\n",
      "[success_episode16_steps70] shape: (70, 199)\n",
      "[success_episode17_steps70] shape: (70, 199)\n",
      "[success_episode18_steps70] shape: (70, 199)\n",
      "[success_episode19_steps70] shape: (70, 199)\n",
      "[success_episode20_steps70] shape: (70, 199)\n",
      "[success_episode21_steps70] shape: (70, 199)\n",
      "[success_episode22_steps70] shape: (70, 199)\n",
      "[success_episode23_steps70] shape: (70, 199)\n",
      "[success_episode24_steps70] shape: (70, 199)\n",
      "[success_episode25_steps70] shape: (70, 199)\n",
      "[success_episode26_steps70] shape: (70, 199)\n",
      "[success_episode27_steps70] shape: (70, 199)\n",
      "[success_episode28_steps70] shape: (70, 199)\n",
      "[success_episode29_steps70] shape: (70, 199)\n",
      "[success_episode30_steps70] shape: (70, 199)\n",
      "[success_episode31_steps70] shape: (70, 199)\n",
      "[success_episode32_steps70] shape: (70, 199)\n",
      "[success_episode33_steps70] shape: (70, 199)\n",
      "[success_episode34_steps70] shape: (70, 199)\n",
      "[success_episode35_steps70] shape: (70, 199)\n",
      "[success_episode36_steps70] shape: (70, 199)\n",
      "[success_episode37_steps70] shape: (70, 199)\n",
      "[success_episode38_steps70] shape: (70, 199)\n",
      "[success_episode39_steps70] shape: (70, 199)\n",
      "[success_episode40_steps70] shape: (70, 199)\n",
      "[success_episode41_steps70] shape: (70, 199)\n",
      "[success_episode42_steps70] shape: (70, 199)\n",
      "[success_episode43_steps70] shape: (70, 199)\n",
      "[success_episode44_steps70] shape: (70, 199)\n",
      "[success_episode45_steps70] shape: (70, 199)\n",
      "[success_episode46_steps70] shape: (70, 199)\n",
      "[success_episode47_steps70] shape: (70, 199)\n",
      "[success_episode48_steps70] shape: (70, 199)\n",
      "[success_episode49_steps70] shape: (70, 199)\n",
      "[success_episode50_steps70] shape: (70, 199)\n",
      "[success_episode51_steps70] shape: (70, 199)\n",
      "[success_episode52_steps70] shape: (70, 199)\n",
      "[success_episode53_steps70] shape: (70, 199)\n",
      "[success_episode54_steps70] shape: (70, 199)\n",
      "[success_episode55_steps70] shape: (70, 199)\n",
      "[success_episode56_steps70] shape: (70, 199)\n",
      "[success_episode57_steps70] shape: (70, 199)\n",
      "[success_episode58_steps70] shape: (70, 199)\n",
      "[success_episode59_steps70] shape: (70, 199)\n",
      "[success_episode60_steps70] shape: (70, 199)\n",
      "[success_episode61_steps70] shape: (70, 199)\n",
      "[success_episode62_steps70] shape: (70, 199)\n",
      "[success_episode63_steps70] shape: (70, 199)\n",
      "[success_episode64_steps70] shape: (70, 199)\n",
      "[success_episode65_steps70] shape: (70, 199)\n",
      "[success_episode66_steps70] shape: (70, 199)\n",
      "[success_episode67_steps70] shape: (70, 199)\n",
      "[success_episode68_steps70] shape: (70, 199)\n",
      "[success_episode69_steps70] shape: (70, 199)\n",
      "[success_episode70_steps70] shape: (70, 199)\n",
      "[success_episode71_steps70] shape: (70, 199)\n",
      "[success_episode72_steps70] shape: (70, 199)\n",
      "[success_episode73_steps70] shape: (70, 199)\n",
      "[success_episode74_steps70] shape: (70, 199)\n",
      "[success_episode75_steps70] shape: (70, 199)\n",
      "\n",
      "✅ Saved merged data to: dataset_natural_fail/fail_data_resnet18_pca_robotO.pkl\n",
      "Total episodes: 75\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "# 경로 설정\n",
    "IMG_ONLY_PATH = \"/AILAB-summer-school-2025/endToEnd_forSuccess/dataset_natural_fail/fail_data_resnet18_pca_robotX.pkl\"\n",
    "ROOT_DIR =  \"/AILAB-summer-school-2025/fail_during_success_data\"   # 입력 루트\n",
    "OUT_PATH = \"dataset_natural_fail/fail_data_resnet18_pca_robotO.pkl\"\n",
    "\n",
    "def coerce_2d_float(arr, dim2=None):\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, arr.shape[0])\n",
    "    if dim2 is not None and arr.shape[1] != dim2:\n",
    "        raise ValueError(f\"Expected shape (?, {dim2}), got {arr.shape}\")\n",
    "    return arr\n",
    "\n",
    "def pick_pose_indexer(T_img: int, T_pose: int):\n",
    "    if T_img == T_pose:\n",
    "        return lambda i: i\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot index: T_img={T_img}, T_pose={T_pose}\")\n",
    "\n",
    "# 기존 이미지 feature 불러오기\n",
    "with open(IMG_ONLY_PATH, \"rb\") as f:\n",
    "    image_data: Dict[str, np.ndarray] = pickle.load(f)\n",
    "\n",
    "new_data = {}\n",
    "import re \n",
    "\n",
    "for key, img_feat in image_data.items():\n",
    "    ep_name = key.split(\"_steps\")[0]  # e.g., success_episode0\n",
    "    T_img = img_feat.shape[0]\n",
    "\n",
    "    # 에피소드 번호 추출\n",
    "    episode_num = int(re.match(r\"success_episode(\\d+)_steps\\d+\", key).group(1))\n",
    "\n",
    "    # 실제 폴더명 검색\n",
    "    matched_folder = None\n",
    "    for name in os.listdir(ROOT_DIR):\n",
    "        if name.startswith(f\"success_episode{episode_num}_steps\"):\n",
    "            matched_folder = name\n",
    "            break\n",
    "    if matched_folder is None:\n",
    "        raise FileNotFoundError(f\"Episode folder for ep {episode_num} not found in {ROOT_DIR}\")\n",
    "\n",
    "    state_path = os.path.join(ROOT_DIR, matched_folder, \"robot_state.npz\")\n",
    "    if not os.path.isfile(state_path):\n",
    "        raise FileNotFoundError(f\"[{ep_name}] robot_state.npz not found: {state_path}\")\n",
    "    \n",
    "    state = np.load(state_path, allow_pickle=True)\n",
    "    if \"EE_pose\" not in state:\n",
    "        raise KeyError(f\"[{ep_name}] 'EE_pose' key not found in robot_state.npz\")\n",
    "\n",
    "    ee_pose = coerce_2d_float(state[\"EE_pose\"], dim2=7)  # (T_pose, 7)\n",
    "    T_pose = ee_pose.shape[0]\n",
    "\n",
    "    indexer = pick_pose_indexer(T_img, T_pose)\n",
    "\n",
    "    ee_pose_seq = np.stack([ee_pose[indexer(i)] for i in range(T_img)], axis=0)  # (T, 7)\n",
    "\n",
    "    merged = np.concatenate([img_feat, ee_pose_seq], axis=1)  # (T, 199)\n",
    "\n",
    "    new_data[key] = merged\n",
    "    print(f\"[{key}] shape: {merged.shape}\")\n",
    "\n",
    "# 저장\n",
    "with open(OUT_PATH, \"wb\") as f:\n",
    "    pickle.dump(new_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"\\n✅ Saved merged data to: {OUT_PATH}\")\n",
    "print(f\"Total episodes: {len(new_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f94587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 파일: success_data_resnet18_pca_robotO.pkl\n",
      "  └ 총 에피소드 수: 516\n",
      "  └ Key: success_episode1_steps64\n",
      "    ├ Type: <class 'numpy.ndarray'>\n",
      "    └ Shape: (64, 199), Dtype: float32\n",
      "       → [:, 0:64] Front | [:, 64:128] Top | [:, 128:192] Wrist | [:, 192:199] State\n",
      "\n",
      "📂 파일: success_data_resnet18_pca_robotX.pkl\n",
      "  └ 총 에피소드 수: 516\n",
      "  └ Key: success_episode1_steps64\n",
      "    ├ Type: <class 'numpy.ndarray'>\n",
      "    └ Shape: (64, 192), Dtype: float32\n",
      "       → [:, 0:64] Front | [:, 64:128] Top | [:, 128:192] Wrist (No State)\n",
      "\n",
      "📂 파일: success_data_resnet18_robotO.pkl\n",
      "  └ 총 에피소드 수: 516\n",
      "  └ Key: success_episode1_steps64\n",
      "    ├ Type: <class 'numpy.ndarray'>\n",
      "    └ Shape: (64, 1543), Dtype: float32\n",
      "       → [:, 0:512] Front | [:, 512:1024] Top | [:, 1024:1536] Wrist | [:, 1536:1543] State\n",
      "\n",
      "📂 파일: success_data_resnet18_robotX.pkl\n",
      "  └ 총 에피소드 수: 516\n",
      "  └ Key: success_episode1_steps64\n",
      "    ├ Type: <class 'numpy.ndarray'>\n",
      "    └ Shape: (64, 1536), Dtype: float32\n",
      "       → [:, 0:512] Front | [:, 512:1024] Top | [:, 1024:1536] Wrist (No State)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "folder = \"/AILAB-summer-school-2025/endToEnd_forSuccess/dataset\"\n",
    "\n",
    "for fname in sorted(os.listdir(folder)):\n",
    "    if not fname.endswith(\".pkl\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(folder, fname)\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    print(f\"\\n📂 파일: {fname}\")\n",
    "    print(f\"  └ 총 에피소드 수: {len(data)}\")\n",
    "\n",
    "    if isinstance(data, dict) and len(data) > 0:\n",
    "        first_key = next(iter(data))\n",
    "        first_value = data[first_key]\n",
    "        print(f\"  └ Key: {first_key}\")\n",
    "        print(f\"    ├ Type: {type(first_value)}\")\n",
    "        if isinstance(first_value, np.ndarray):\n",
    "            T, D = first_value.shape\n",
    "\n",
    "            # robot 뒤에 숫자(=O/X가 아닌)가 있으면 state 있음\n",
    "            after_robot = fname.split(\"robot\")[-1]\n",
    "            has_state = not after_robot.startswith(\"X\")\n",
    "\n",
    "            if has_state:\n",
    "                D_state = 7\n",
    "                D_image = D - D_state\n",
    "                D_view = D_image // 3\n",
    "                print(f\"    └ Shape: ({T}, {D}), Dtype: {first_value.dtype}\")\n",
    "                print(f\"       → [:, 0:{D_view}] Front | [:, {D_view}:{2*D_view}] Top | [:, {2*D_view}:{3*D_view}] Wrist | [:, {3*D_view}:{D}] State\")\n",
    "            else:\n",
    "                D_view = D // 3\n",
    "                print(f\"    └ Shape: ({T}, {D}), Dtype: {first_value.dtype}\")\n",
    "                print(f\"       → [:, 0:{D_view}] Front | [:, {D_view}:{2*D_view}] Top | [:, {2*D_view}:{D}] Wrist (No State)\")\n",
    "        else:\n",
    "            print(f\"    └ Value (preview): {str(first_value)[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884db624",
   "metadata": {},
   "source": [
    "#실패 데이터 전처리\n",
    "4가지 전처리 과정이 포함됩니다.\n",
    "\n",
    "resent18<br>\n",
    "resent18 + robotdata<br>\n",
    "resnet18 -> pca<br>\n",
    "resnet18 -> pca + robotdata<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fail1_episode1_step70_noise37 ...\n",
      "Processing fail1_episode2_step70_noise38 ...\n",
      "Processing fail1_episode3_step70_noise35 ...\n",
      "Processing fail1_episode4_step70_noise35 ...\n",
      "Processing fail1_episode5_step70_noise35 ...\n",
      "Processing fail2_episode1_step70_noise7 ...\n",
      "Processing fail2_episode2_step70_noise7 ...\n",
      "Processing fail2_episode3_step70_noise7 ...\n",
      "Processing fail2_episode4_step70_noise7 ...\n",
      "Processing fail2_episode5_step70_noise7 ...\n",
      "Processing fail3_episode1_step70_noise41 ...\n",
      "Processing fail3_episode2_step70_noise41 ...\n",
      "Processing fail3_episode3_step70_noise41 ...\n",
      "Processing fail3_episode4_step70_noise41 ...\n",
      "Processing fail3_episode5_step70_noise41 ...\n",
      "Processing fail4_episode1_step70_noise49 ...\n",
      "Processing fail4_episode2_step70_noise46 ...\n",
      "Processing fail4_episode3_step70_noise49 ...\n",
      "Processing fail4_episode4_step70_noise50 ...\n",
      "Processing fail4_episode5_step70_noise50 ...\n",
      "Processing fail5_episode4_step70_noise1 ...\n",
      "Processing fail5_episode5_step70_noise1 ...\n",
      "[Warning] unexpected folder name \"success5_episode1_step323\", skipping.\n",
      "[Warning] unexpected folder name \"success5_episode2_step312\", skipping.\n",
      "[Warning] unexpected folder name \"success5_episode3_step287\", skipping.\n",
      "Saved processed data to dataset/fail_data_resnet18_robotX.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "apply resent18 (for fail)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"fail{case_number}_episode{episode_number}_steps{episode_length//5+1}_noise{noise_step//5+1}\":\n",
    "        [episode_length//5+1, 512*3] #front, top, wrist\n",
    "    }\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "apply resnet18 -> pca (for fail)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"fail{case_number}_episode{episode_number}_steps{episode_length//5+1}_noise{noise_step//5+1}\":\n",
    "        [episode_length//5+1, 64*3] #front, top, wrist\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import re\n",
    "\n",
    "def load_resnet_feature_extractor(device):\n",
    "    # pretrained ResNet-18, 마지막 fc 층 Identity로 대체\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = torch.nn.Identity()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_pca_model(view):\n",
    "    pca_path = f'model/model_pca_{view}_view.pkl'\n",
    "    with open(pca_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_sorted_image_paths(dir_path, view):\n",
    "    # view_view_#.png 에서 # 추출 후 오름차순 정렬\n",
    "    pattern = re.compile(fr'{view}_view_(\\d+)\\.png')\n",
    "    files = []\n",
    "    for fname in os.listdir(dir_path):\n",
    "        m = pattern.match(fname)\n",
    "        if m:\n",
    "            idx = int(m.group(1))\n",
    "            files.append((idx, os.path.join(dir_path, fname)))\n",
    "    files.sort(key=lambda x: x[0])\n",
    "    return [path for _, path in files]\n",
    "\n",
    "def process_episode(ep_dir, model, pca_models, device):\n",
    "    # 1) robot_state.npz에서 EE pose 불러오기\n",
    "    state = np.load(os.path.join(ep_dir, 'robot_state.npz'))\n",
    "    if 'eepose' in state:\n",
    "        ee_pose = state['eepose']           # shape (T,7)\n",
    "    elif 'EE_pose' in state:\n",
    "        ee_pose = state['EE_pose']\n",
    "    else:\n",
    "        raise KeyError(f'EE pose key not found in {ep_dir}/robot_state.npz')\n",
    "\n",
    "    # 2) 이미지 전처리 트랜스폼\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                             std= [0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    # 3) 각 view별로 ResNet → PCA\n",
    "    latents = []\n",
    "    with torch.no_grad():\n",
    "        for view in ['front', 'top', 'wrist']:\n",
    "            view_dir = os.path.join(ep_dir, f'{view}_view')\n",
    "            img_paths = get_sorted_image_paths(view_dir, view)\n",
    "            feats512 = []\n",
    "            for img_path in img_paths:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                x = transform(img).unsqueeze(0).to(device)\n",
    "                f512 = model(x).cpu().numpy().reshape(-1)  # (512,)\n",
    "                feats512.append(f512)\n",
    "            feats512 = np.stack(feats512, axis=0)           # (T,512)\n",
    "            #feats64  = pca_models[view].transform(feats512) # (T,64)\n",
    "            latents.append(feats512)\n",
    "\n",
    "    # 4) front+top+wrist+ee_pose 합치기 → (T,199)\n",
    "    data_episode = np.concatenate([latents[0], latents[1], latents[2]], axis=1)\n",
    "    return data_episode\n",
    "\n",
    "def main():\n",
    "    root_dir = '/AILAB-summer-school-2025/fail_data_raw'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # ResNet-18 & PCA 모델 로드\n",
    "    model = load_resnet_feature_extractor(device)\n",
    "    pca_models = {\n",
    "        view: load_pca_model(view)\n",
    "        for view in ['front', 'top', 'wrist']\n",
    "    }\n",
    "\n",
    "    processed = {}\n",
    "    # 케이스 디렉토리 순회\n",
    "    for case_name in sorted(os.listdir(root_dir)):\n",
    "        case_dir = os.path.join(root_dir, case_name)\n",
    "        if not os.path.isdir(case_dir):\n",
    "            continue\n",
    "\n",
    "        # 각 에피소드 디렉토리 순회\n",
    "        for ep_name in sorted(os.listdir(case_dir)):\n",
    "            ep_dir = os.path.join(case_dir, ep_name)\n",
    "            if not os.path.isdir(ep_dir):\n",
    "                continue\n",
    "\n",
    "            # 정규표현식으로 정확히 fail{n}_episode{m}_step{s}_noise{v} 패턴만 매칭\n",
    "            m = re.match(r'^(fail\\d+)_episode(\\d+)_step(\\d+)_noise(\\d+)$', ep_name)\n",
    "            if not m:\n",
    "                print(f'[Warning] unexpected folder name \"{ep_name}\", skipping.')\n",
    "                continue\n",
    "\n",
    "            fail_str       = m.group(1)             # ex) 'fail1'\n",
    "            episode_num    = m.group(2)             # ex) '2'\n",
    "            step_len       = int(m.group(3)) //5 +1\n",
    "            noise_val      = int(m.group(4))        # ex) 180\n",
    "            noise_idx      = noise_val // 5 + 1     # 5로 나눈 몫 + 1\n",
    "            key            = f'{fail_str}_episode{episode_num}_step{step_len}_noise{noise_idx}'\n",
    "            print(f'Processing {key} ...')\n",
    "            processed[key] = process_episode(ep_dir, model, pca_models, device)\n",
    "\n",
    "    # 결과 저장\n",
    "    out_path = 'dataset/fail_data_resnet18_robotX.pkl'\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(processed, f)\n",
    "    print(f'Saved processed data to {out_path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "apply resent18 + robotdata (for fail)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"fail{case_number}_episode{episode_number}_steps{episode_length//5+1}_noise{noise_step//5+1}\":\n",
    "        [episode_length//5+1, 512*3+7] #front, top, wrist, robot_data\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import re\n",
    "\n",
    "def load_resnet_feature_extractor(device):\n",
    "    # pretrained ResNet-18, 마지막 fc 층 Identity로 대체\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = torch.nn.Identity()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_pca_model(view):\n",
    "    pca_path = f'model/model_pca_{view}_view.pkl'\n",
    "    with open(pca_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_sorted_image_paths(dir_path, view):\n",
    "    # view_view_#.png 에서 # 추출 후 오름차순 정렬\n",
    "    pattern = re.compile(fr'{view}_view_(\\d+)\\.png')\n",
    "    files = []\n",
    "    for fname in os.listdir(dir_path):\n",
    "        m = pattern.match(fname)\n",
    "        if m:\n",
    "            idx = int(m.group(1))\n",
    "            files.append((idx, os.path.join(dir_path, fname)))\n",
    "    files.sort(key=lambda x: x[0])\n",
    "    return [path for _, path in files]\n",
    "\n",
    "def process_episode(ep_dir, model, pca_models, device):\n",
    "    # 1) robot_state.npz에서 EE pose 불러오기\n",
    "    state = np.load(os.path.join(ep_dir, 'robot_state.npz'))\n",
    "    if 'eepose' in state:\n",
    "        ee_pose = state['eepose']           # shape (T,7)\n",
    "    elif 'EE_pose' in state:\n",
    "        ee_pose = state['EE_pose']\n",
    "    else:\n",
    "        raise KeyError(f'EE pose key not found in {ep_dir}/robot_state.npz')\n",
    "\n",
    "    # 2) 이미지 전처리 트랜스폼\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                             std= [0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    # 3) 각 view별로 ResNet → PCA\n",
    "    latents = []\n",
    "    with torch.no_grad():\n",
    "        for view in ['front', 'top', 'wrist']:\n",
    "            view_dir = os.path.join(ep_dir, f'{view}_view')\n",
    "            img_paths = get_sorted_image_paths(view_dir, view)\n",
    "            feats512 = []\n",
    "            for img_path in img_paths:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                x = transform(img).unsqueeze(0).to(device)\n",
    "                f512 = model(x).cpu().numpy().reshape(-1)  # (512,)\n",
    "                feats512.append(f512)\n",
    "            feats512 = np.stack(feats512, axis=0)           # (T,512)\n",
    "            #feats64  = pca_models[view].transform(feats512) # (T,64)\n",
    "            latents.append(feats512)\n",
    "\n",
    "    # 4) front+top+wrist+ee_pose 합치기 → (T,199)\n",
    "    data_episode = np.concatenate([latents[0], latents[1], latents[2], ee_pose], axis=1)\n",
    "    return data_episode\n",
    "\n",
    "def main():\n",
    "    root_dir = '/AILAB-summer-school-2025/fail_data_raw'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # ResNet-18 & PCA 모델 로드\n",
    "    model = load_resnet_feature_extractor(device)\n",
    "    pca_models = {\n",
    "        view: load_pca_model(view)\n",
    "        for view in ['front', 'top', 'wrist']\n",
    "    }\n",
    "\n",
    "    processed = {}\n",
    "    # 케이스 디렉토리 순회\n",
    "    for case_name in sorted(os.listdir(root_dir)):\n",
    "        case_dir = os.path.join(root_dir, case_name)\n",
    "        if not os.path.isdir(case_dir):\n",
    "            continue\n",
    "\n",
    "        # 각 에피소드 디렉토리 순회\n",
    "        for ep_name in sorted(os.listdir(case_dir)):\n",
    "            ep_dir = os.path.join(case_dir, ep_name)\n",
    "            if not os.path.isdir(ep_dir):\n",
    "                continue\n",
    "\n",
    "            # 정규표현식으로 정확히 fail{n}_episode{m}_step{s}_noise{v} 패턴만 매칭\n",
    "            m = re.match(r'^(fail\\d+)_episode(\\d+)_step(\\d+)_noise(\\d+)$', ep_name)\n",
    "            if not m:\n",
    "                print(f'[Warning] unexpected folder name \"{ep_name}\", skipping.')\n",
    "                continue\n",
    "\n",
    "            fail_str       = m.group(1)             # ex) 'fail1'\n",
    "            episode_num    = m.group(2)             # ex) '2'\n",
    "            step_len       = int(m.group(3)) //5 +1\n",
    "            noise_val      = int(m.group(4))        # ex) 180\n",
    "            noise_idx      = noise_val // 5 + 1     # 5로 나눈 몫 + 1\n",
    "            key            = f'{fail_str}_episode{episode_num}_step{step_len}_noise{noise_idx}'\n",
    "            print(f'Processing {key} ...')\n",
    "            processed[key] = process_episode(ep_dir, model, pca_models, device)\n",
    "\n",
    "    # 결과 저장\n",
    "    out_path = 'dataset/fail_data_resnet18_robotO.pkl'\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(processed, f)\n",
    "    print(f'Saved processed data to {out_path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9715df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fail1_episode1_step70_noise37 ...\n",
      "Processing fail1_episode2_step70_noise38 ...\n",
      "Processing fail1_episode3_step70_noise35 ...\n",
      "Processing fail1_episode4_step70_noise35 ...\n",
      "Processing fail1_episode5_step70_noise35 ...\n",
      "Processing fail2_episode1_step70_noise7 ...\n",
      "Processing fail2_episode2_step70_noise7 ...\n",
      "Processing fail2_episode3_step70_noise7 ...\n",
      "Processing fail2_episode4_step70_noise7 ...\n",
      "Processing fail2_episode5_step70_noise7 ...\n",
      "Processing fail3_episode1_step70_noise41 ...\n",
      "Processing fail3_episode2_step70_noise41 ...\n",
      "Processing fail3_episode3_step70_noise41 ...\n",
      "Processing fail3_episode4_step70_noise41 ...\n",
      "Processing fail3_episode5_step70_noise41 ...\n",
      "Processing fail4_episode1_step70_noise49 ...\n",
      "Processing fail4_episode2_step70_noise46 ...\n",
      "Processing fail4_episode3_step70_noise49 ...\n",
      "Processing fail4_episode4_step70_noise50 ...\n",
      "Processing fail4_episode5_step70_noise50 ...\n",
      "Processing fail5_episode4_step70_noise1 ...\n",
      "Processing fail5_episode5_step70_noise1 ...\n",
      "[Warning] unexpected folder name \"success5_episode1_step323\", skipping.\n",
      "[Warning] unexpected folder name \"success5_episode2_step312\", skipping.\n",
      "[Warning] unexpected folder name \"success5_episode3_step287\", skipping.\n",
      "Saved processed data to dataset/fail_data_resnet18_pca_robotX.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "apply resnet18 -> pca (for fail)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"fail{case_number}_episode{episode_number}_steps{episode_length//5+1}_noise{noise_step//5+1}\":\n",
    "        [episode_length//5+1, 64*3] #front, top, wrist\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import re\n",
    "\n",
    "def load_resnet_feature_extractor(device):\n",
    "    # pretrained ResNet-18, 마지막 fc 층 Identity로 대체\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = torch.nn.Identity()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_pca_model(view):\n",
    "    pca_path = f'model/model_pca_{view}_view.pkl'\n",
    "    with open(pca_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_sorted_image_paths(dir_path, view):\n",
    "    # view_view_#.png 에서 # 추출 후 오름차순 정렬\n",
    "    pattern = re.compile(fr'{view}_view_(\\d+)\\.png')\n",
    "    files = []\n",
    "    for fname in os.listdir(dir_path):\n",
    "        m = pattern.match(fname)\n",
    "        if m:\n",
    "            idx = int(m.group(1))\n",
    "            files.append((idx, os.path.join(dir_path, fname)))\n",
    "    files.sort(key=lambda x: x[0])\n",
    "    return [path for _, path in files]\n",
    "\n",
    "def process_episode(ep_dir, model, pca_models, device):\n",
    "    # 1) robot_state.npz에서 EE pose 불러오기\n",
    "    state = np.load(os.path.join(ep_dir, 'robot_state.npz'))\n",
    "    if 'eepose' in state:\n",
    "        ee_pose = state['eepose']           # shape (T,7)\n",
    "    elif 'EE_pose' in state:\n",
    "        ee_pose = state['EE_pose']\n",
    "    else:\n",
    "        raise KeyError(f'EE pose key not found in {ep_dir}/robot_state.npz')\n",
    "\n",
    "    # 2) 이미지 전처리 트랜스폼\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                             std= [0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    # 3) 각 view별로 ResNet → PCA\n",
    "    latents = []\n",
    "    with torch.no_grad():\n",
    "        for view in ['front', 'top', 'wrist']:\n",
    "            view_dir = os.path.join(ep_dir, f'{view}_view')\n",
    "            img_paths = get_sorted_image_paths(view_dir, view)\n",
    "            feats512 = []\n",
    "            for img_path in img_paths:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                x = transform(img).unsqueeze(0).to(device)\n",
    "                f512 = model(x).cpu().numpy().reshape(-1)  # (512,)\n",
    "                feats512.append(f512)\n",
    "            feats512 = np.stack(feats512, axis=0)           # (T,512)\n",
    "            feats64  = pca_models[view].transform(feats512) # (T,64)\n",
    "            latents.append(feats64)\n",
    "\n",
    "    # 4) front+top+wrist+ee_pose 합치기 → (T,199)\n",
    "    data_episode = np.concatenate([latents[0], latents[1], latents[2]], axis=1)\n",
    "    return data_episode\n",
    "\n",
    "def main():\n",
    "    root_dir = '/AILAB-summer-school-2025/fail_data_raw'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # ResNet-18 & PCA 모델 로드\n",
    "    model = load_resnet_feature_extractor(device)\n",
    "    pca_models = {\n",
    "        view: load_pca_model(view)\n",
    "        for view in ['front', 'top', 'wrist']\n",
    "    }\n",
    "\n",
    "    processed = {}\n",
    "    # 케이스 디렉토리 순회\n",
    "    for case_name in sorted(os.listdir(root_dir)):\n",
    "        case_dir = os.path.join(root_dir, case_name)\n",
    "        if not os.path.isdir(case_dir):\n",
    "            continue\n",
    "\n",
    "        # 각 에피소드 디렉토리 순회\n",
    "        for ep_name in sorted(os.listdir(case_dir)):\n",
    "            ep_dir = os.path.join(case_dir, ep_name)\n",
    "            if not os.path.isdir(ep_dir):\n",
    "                continue\n",
    "\n",
    "            # 정규표현식으로 정확히 fail{n}_episode{m}_step{s}_noise{v} 패턴만 매칭\n",
    "            m = re.match(r'^(fail\\d+)_episode(\\d+)_step(\\d+)_noise(\\d+)$', ep_name)\n",
    "            if not m:\n",
    "                print(f'[Warning] unexpected folder name \"{ep_name}\", skipping.')\n",
    "                continue\n",
    "\n",
    "            fail_str       = m.group(1)             # ex) 'fail1'\n",
    "            episode_num    = m.group(2)             # ex) '2'\n",
    "            step_len       = int(m.group(3)) //5 +1\n",
    "            noise_val      = int(m.group(4))        # ex) 180\n",
    "            noise_idx      = noise_val // 5 + 1     # 5로 나눈 몫 + 1\n",
    "            key            = f'{fail_str}_episode{episode_num}_step{step_len}_noise{noise_idx}'\n",
    "            print(f'Processing {key} ...')\n",
    "            processed[key] = process_episode(ep_dir, model, pca_models, device)\n",
    "\n",
    "    # 결과 저장\n",
    "    out_path = 'dataset/fail_data_resnet18_pca_robotX.pkl'\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(processed, f)\n",
    "    print(f'Saved processed data to {out_path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bc6a0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fail1_episode1_step70_noise37 ...\n",
      "Processing fail1_episode2_step70_noise38 ...\n",
      "Processing fail1_episode3_step70_noise35 ...\n",
      "Processing fail1_episode4_step70_noise35 ...\n",
      "Processing fail1_episode5_step70_noise35 ...\n",
      "Processing fail2_episode1_step70_noise7 ...\n",
      "Processing fail2_episode2_step70_noise7 ...\n",
      "Processing fail2_episode3_step70_noise7 ...\n",
      "Processing fail2_episode4_step70_noise7 ...\n",
      "Processing fail2_episode5_step70_noise7 ...\n",
      "Processing fail3_episode1_step70_noise41 ...\n",
      "Processing fail3_episode2_step70_noise41 ...\n",
      "Processing fail3_episode3_step70_noise41 ...\n",
      "Processing fail3_episode4_step70_noise41 ...\n",
      "Processing fail3_episode5_step70_noise41 ...\n",
      "Processing fail4_episode1_step70_noise49 ...\n",
      "Processing fail4_episode2_step70_noise46 ...\n",
      "Processing fail4_episode3_step70_noise49 ...\n",
      "Processing fail4_episode4_step70_noise50 ...\n",
      "Processing fail4_episode5_step70_noise50 ...\n",
      "Processing fail5_episode4_step70_noise1 ...\n",
      "Processing fail5_episode5_step70_noise1 ...\n",
      "[Warning] unexpected folder name \"success5_episode1_step323\", skipping.\n",
      "[Warning] unexpected folder name \"success5_episode2_step312\", skipping.\n",
      "[Warning] unexpected folder name \"success5_episode3_step287\", skipping.\n",
      "Saved processed data to dataset/fail_data_resnet18_pca_robotO.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "apply resnet18 -> pca + robotdata (for fail)\n",
    "\n",
    "structure\n",
    "data = {\n",
    "    \"fail{case_number}_episode{episode_number}_steps{episode_length//5+1}_noise{noise_step//5+1}\":\n",
    "        [episode_length//5+1, 64*3+7] #front, top, wrist, robot_data\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import re\n",
    "\n",
    "def load_resnet_feature_extractor(device):\n",
    "    # pretrained ResNet-18, 마지막 fc 층 Identity로 대체\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = torch.nn.Identity()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_pca_model(view):\n",
    "    pca_path = f'model/model_pca_{view}_view.pkl'\n",
    "    with open(pca_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def get_sorted_image_paths(dir_path, view):\n",
    "    # view_view_#.png 에서 # 추출 후 오름차순 정렬\n",
    "    pattern = re.compile(fr'{view}_view_(\\d+)\\.png')\n",
    "    files = []\n",
    "    for fname in os.listdir(dir_path):\n",
    "        m = pattern.match(fname)\n",
    "        if m:\n",
    "            idx = int(m.group(1))\n",
    "            files.append((idx, os.path.join(dir_path, fname)))\n",
    "    files.sort(key=lambda x: x[0])\n",
    "    return [path for _, path in files]\n",
    "\n",
    "def process_episode(ep_dir, model, pca_models, device):\n",
    "    # 1) robot_state.npz에서 EE pose 불러오기\n",
    "    state = np.load(os.path.join(ep_dir, 'robot_state.npz'))\n",
    "    if 'eepose' in state:\n",
    "        ee_pose = state['eepose']           # shape (T,7)\n",
    "    elif 'EE_pose' in state:\n",
    "        ee_pose = state['EE_pose']\n",
    "    else:\n",
    "        raise KeyError(f'EE pose key not found in {ep_dir}/robot_state.npz')\n",
    "\n",
    "    # 2) 이미지 전처리 트랜스폼\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                             std= [0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    # 3) 각 view별로 ResNet → PCA\n",
    "    latents = []\n",
    "    with torch.no_grad():\n",
    "        for view in ['front', 'top', 'wrist']:\n",
    "            view_dir = os.path.join(ep_dir, f'{view}_view')\n",
    "            img_paths = get_sorted_image_paths(view_dir, view)\n",
    "            feats512 = []\n",
    "            for img_path in img_paths:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                x = transform(img).unsqueeze(0).to(device)\n",
    "                f512 = model(x).cpu().numpy().reshape(-1)  # (512,)\n",
    "                feats512.append(f512)\n",
    "            feats512 = np.stack(feats512, axis=0)           # (T,512)\n",
    "            feats64  = pca_models[view].transform(feats512) # (T,64)\n",
    "            latents.append(feats64)\n",
    "\n",
    "    # 4) front+top+wrist+ee_pose 합치기 → (T,199)\n",
    "    data_episode = np.concatenate([latents[0], latents[1], latents[2], ee_pose], axis=1)\n",
    "    return data_episode\n",
    "\n",
    "def main():\n",
    "    root_dir = '/AILAB-summer-school-2025/fail_data_raw'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # ResNet-18 & PCA 모델 로드\n",
    "    model = load_resnet_feature_extractor(device)\n",
    "    pca_models = {\n",
    "        view: load_pca_model(view)\n",
    "        for view in ['front', 'top', 'wrist']\n",
    "    }\n",
    "\n",
    "    processed = {}\n",
    "    # 케이스 디렉토리 순회\n",
    "    for case_name in sorted(os.listdir(root_dir)):\n",
    "        case_dir = os.path.join(root_dir, case_name)\n",
    "        if not os.path.isdir(case_dir):\n",
    "            continue\n",
    "\n",
    "        # 각 에피소드 디렉토리 순회\n",
    "        for ep_name in sorted(os.listdir(case_dir)):\n",
    "            ep_dir = os.path.join(case_dir, ep_name)\n",
    "            if not os.path.isdir(ep_dir):\n",
    "                continue\n",
    "\n",
    "            # 정규표현식으로 정확히 fail{n}_episode{m}_step{s}_noise{v} 패턴만 매칭\n",
    "            m = re.match(r'^(fail\\d+)_episode(\\d+)_step(\\d+)_noise(\\d+)$', ep_name)\n",
    "            if not m:\n",
    "                print(f'[Warning] unexpected folder name \"{ep_name}\", skipping.')\n",
    "                continue\n",
    "\n",
    "            fail_str       = m.group(1)             # ex) 'fail1'\n",
    "            episode_num    = m.group(2)             # ex) '2'\n",
    "            step_len       = int(m.group(3)) //5 +1\n",
    "            noise_val      = int(m.group(4))        # ex) 180\n",
    "            noise_idx      = noise_val // 5 + 1     # 5로 나눈 몫 + 1\n",
    "            key            = f'{fail_str}_episode{episode_num}_step{step_len}_noise{noise_idx}'\n",
    "            print(f'Processing {key} ...')\n",
    "            processed[key] = process_episode(ep_dir, model, pca_models, device)\n",
    "\n",
    "    # 결과 저장\n",
    "    out_path = 'dataset/fail_data_resnet18_pca_robotO.pkl'\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(processed, f)\n",
    "    print(f'Saved processed data to {out_path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
