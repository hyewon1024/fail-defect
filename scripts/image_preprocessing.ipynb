{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b8a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-Only Processor Config\n",
      "Views: ['front', 'top', 'wrist']\n",
      "ResNet Features: 512 per view\n",
      "Compressed Features: 64 per view\n",
      "Total Compressed: 192\n",
      "Device: cuda\n",
      "[INFO] ResNet18 feature extractor initialized on cuda\n",
      "[INFO] Found 5 episodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████| 5/5 [00:00<00:00, 25795.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp\n",
      "[WARN] Skipping /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp: No robot_state.npz found in /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp\n",
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case4_release\n",
      "[WARN] Skipping /AILAB-summer-school-2025/fail_data_raw/fail_case4_release: No robot_state.npz found in /AILAB-summer-school-2025/fail_data_raw/fail_case4_release\n",
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp\n",
      "[WARN] Skipping /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp: No robot_state.npz found in /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp\n",
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin\n",
      "[WARN] Skipping /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin: No robot_state.npz found in /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin\n",
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case5_light\n",
      "[WARN] Skipping /AILAB-summer-school-2025/fail_data_raw/fail_case5_light: No robot_state.npz found in /AILAB-summer-school-2025/fail_data_raw/fail_case5_light\n",
      "[INFO] Fitting PCA models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 197\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[WARN] Skipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepi_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Step 3. PCA 학습 (view별)\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_pca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_episode_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Step 4. PCA 압축 적용 및 저장\u001b[39;00m\n\u001b[1;32m    200\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompressed_episodes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 122\u001b[0m, in \u001b[0;36mEpisodeProcessor.fit_pca\u001b[0;34m(self, all_episode_features)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Fitting PCA models...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m total_img_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mVIEWS) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mRESNET_FEATURE_DIM\n\u001b[0;32m--> 122\u001b[0m sample_feat \u001b[38;5;241m=\u001b[39m \u001b[43mall_episode_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    123\u001b[0m state_dim \u001b[38;5;241m=\u001b[39m sample_feat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m total_img_dim\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Detected state_dim = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# success case \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "@dataclass\n",
    "class ImageOnlyConfig:\n",
    "    \"\"\"Configuration for image-only processing\"\"\"\n",
    "    \n",
    "    # ===== PATHS =====\n",
    "    IMAGE_FOLDER: str = \"success_traj_img\"\n",
    "    \n",
    "    OUTPUT_PATH: str = \"image_features.npz\"\n",
    "    PCA_MODEL_PATH: str = \"image_pca_models.pkl\"\n",
    "    \n",
    "    # ===== IMAGE PROCESSING =====\n",
    "    RESNET_FEATURE_DIM: int = 512  # ResNet18 final layer per view\n",
    "    VIEWS: List[str] = None\n",
    "    \n",
    "    # ===== PCA COMPRESSION =====\n",
    "    COMPRESSED_DIM: int = 64  # Final compressed dimension per view\n",
    "    TOTAL_COMPRESSED_DIM: int = 192  # 64 * 3 views\n",
    "    \n",
    "    # ===== MODEL =====\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE: int = 32\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.VIEWS is None:\n",
    "            self.VIEWS = [\"front\", \"top\", \"wrist\"]\n",
    "        \n",
    "        print(f\"Image-Only Processor Config\")\n",
    "        print(f\"Views: {self.VIEWS}\")\n",
    "        print(f\"ResNet Features: {self.RESNET_FEATURE_DIM} per view\")\n",
    "        print(f\"Compressed Features: {self.COMPRESSED_DIM} per view\")\n",
    "        print(f\"Total Compressed: {self.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"Device: {self.DEVICE}\")\n",
    "\n",
    "class EpisodeProcessor:\n",
    "    def __init__(self, config: ImageOnlyConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.DEVICE)\n",
    "\n",
    "        # ResNet18 feature extractor\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.pca_models = {}\n",
    "        print(f\"[INFO] ResNet18 feature extractor initialized on {self.device}\")\n",
    "\n",
    "    def extract_features(self, image_path: str) -> np.ndarray:\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                features = self.model(image_tensor).view(1, -1)\n",
    "            return features.cpu().numpy().flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to process {image_path}: {e}\")\n",
    "            return np.zeros(self.config.RESNET_FEATURE_DIM)\n",
    "\n",
    "    def process_episode(self, episode_dir: str) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Process a single episode directory\"\"\"\n",
    "        print(f\"[INFO] Processing episode: {episode_dir}\")\n",
    "        \n",
    "        # Load robot state\n",
    "        state_path = os.path.join(episode_dir, \"robot_state.npz\")\n",
    "        if not os.path.exists(state_path):\n",
    "            raise FileNotFoundError(f\"No robot_state.npz found in {episode_dir}\")\n",
    "        state_data = np.load(state_path)\n",
    "        state_key = list(state_data.keys())[0]  \n",
    "        robot_states = state_data[state_key]\n",
    "        print(f\"[INFO] Robot state shape: {robot_states.shape}\")\n",
    "\n",
    "        # Build timestep list\n",
    "        front_dir = os.path.join(episode_dir, \"front_view\")\n",
    "        timesteps = sorted([\n",
    "            int(f.split('_')[-1].replace('.png', ''))\n",
    "            for f in os.listdir(front_dir) if f.endswith('.png')\n",
    "        ])\n",
    "\n",
    "        features = []\n",
    "        for i, ts in enumerate(timesteps):\n",
    "            view_feats = []\n",
    "            for view in self.config.VIEWS:\n",
    "                img_path = os.path.join(episode_dir, f\"{view}_view\", f\"{view}_view_{ts}.png\")\n",
    "                feat = self.extract_features(img_path)\n",
    "                view_feats.append(feat)\n",
    "\n",
    "            combined_img_feat = np.concatenate(view_feats)  # [1536]\n",
    "            features.append(np.concatenate([combined_img_feat, robot_states[i]]))\n",
    "\n",
    "        return {\"observation\": np.vstack(features)}\n",
    "\n",
    "    def fit_pca(self, all_episode_features: List[np.ndarray]):\n",
    "        \"\"\"Fit PCA per view across all episodes\"\"\"\n",
    "        print(\"[INFO] Fitting PCA models...\")\n",
    "\n",
    "        total_img_dim = len(self.config.VIEWS) * self.config.RESNET_FEATURE_DIM\n",
    "        sample_feat = all_episode_features[0]\n",
    "        state_dim = sample_feat.shape[1] - total_img_dim\n",
    "        print(f\"[INFO] Detected state_dim = {state_dim}\")\n",
    "\n",
    "        view_features = {view: [] for view in self.config.VIEWS}\n",
    "\n",
    "        for episode_feat in all_episode_features:\n",
    "            img_feats = episode_feat[:, :-state_dim]\n",
    "            for i, view in enumerate(self.config.VIEWS):\n",
    "                start, end = i * self.config.RESNET_FEATURE_DIM, (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                view_features[view].append(img_feats[:, start:end])\n",
    "\n",
    "        for view in self.config.VIEWS:\n",
    "            X = np.vstack(view_features[view])  # (N*T, 512)\n",
    "            pca = PCA(n_components=self.config.COMPRESSED_DIM)\n",
    "            pca.fit(X)\n",
    "            self.pca_models[view] = pca\n",
    "            print(f\"[INFO] {view} view PCA variance explained: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "    def compress_episode(self, episode_dict: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Apply PCA compression to images, concat state as-is\"\"\"\n",
    "        obs = episode_dict[\"observation\"]\n",
    "        total_img_dim = len(self.config.VIEWS) * self.config.RESNET_FEATURE_DIM\n",
    "        state_dim = obs.shape[1] - total_img_dim\n",
    "\n",
    "        img_feats, state_feats = obs[:, :-state_dim], obs[:, -state_dim:]\n",
    "\n",
    "        compressed_features = []\n",
    "        for row in img_feats:\n",
    "            comp_views = []\n",
    "            for i, view in enumerate(self.config.VIEWS):\n",
    "                start, end = i*self.config.RESNET_FEATURE_DIM, (i+1)*self.config.RESNET_FEATURE_DIM\n",
    "                view_feat = row[start:end].reshape(1, -1)\n",
    "                comp_views.append(self.pca_models[view].transform(view_feat).flatten())\n",
    "            compressed_features.append(np.concatenate(comp_views))\n",
    "\n",
    "        compressed_features = np.vstack(compressed_features)\n",
    "        final_obs = np.hstack([compressed_features, state_feats])  # PCA된 이미지 + 원본 state\n",
    "        return {\"observation\": final_obs}\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = ImageOnlyConfig(\n",
    "        IMAGE_FOLDER=\"/AILAB-summer-school-2025/success_data_raw\", # image path \n",
    "        OUTPUT_PATH=\"success_data_preprocessing\",\n",
    "        PCA_MODEL_PATH=\"pca_models.pkl\",\n",
    "        COMPRESSED_DIM=64\n",
    "    )\n",
    "    processor = EpisodeProcessor(config)\n",
    "\n",
    "    # Step 1. 전체 episode 폴더 탐색\n",
    "    episode_dirs = [\n",
    "        os.path.join(config.IMAGE_FOLDER, d)\n",
    "        for d in os.listdir(config.IMAGE_FOLDER)\n",
    "        if os.path.isdir(os.path.join(config.IMAGE_FOLDER, d))\n",
    "        and (\"success_\" in d or \"fail_\" in d)\n",
    "    ]\n",
    "    print(f\"[INFO] Found {len(episode_dirs)} episodes.\")\n",
    "\n",
    "    # Step 2. 각 episode feature 추출\n",
    "    all_episode_features = []\n",
    "    raw_episode_dicts = {}\n",
    "    for epi_dir in tqdm(episode_dirs, desc=\"Processing episodes\"):\n",
    "        try:\n",
    "            epi_name = os.path.basename(epi_dir)\n",
    "            episode_dict = processor.process_episode(epi_dir)  # raw features + state\n",
    "            raw_episode_dicts[epi_name] = episode_dict\n",
    "            all_episode_features.append(episode_dict[\"observation\"])\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipping {epi_dir}: {e}\")\n",
    "\n",
    "    # Step 3. PCA 학습 (view별)\n",
    "    processor.fit_pca(all_episode_features)\n",
    "\n",
    "    # Step 4. PCA 압축 적용 및 저장\n",
    "    output_dir = \"compressed_episodes\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for epi_name, epi_dict in raw_episode_dicts.items():\n",
    "        compressed_dict = processor.compress_episode(epi_dict)\n",
    "\n",
    "        save_path = os.path.join(output_dir, f\"{epi_name}.npz\")\n",
    "        np.savez_compressed(save_path, **compressed_dict)\n",
    "        \n",
    "        print(f\"[INFO] Saved compressed episode: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092a0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-Only Processor Config\n",
      "Views: ['front', 'top', 'wrist']\n",
      "ResNet Features: 512 per view\n",
      "Compressed Features: 64 per view\n",
      "Total Compressed: 192\n",
      "Device: cuda\n",
      "[INFO] ResNet18 feature extractor initialized on cuda\n",
      "[INFO] Found 22 episodes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp/fail1_episode5_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:   5%|▍         | 1/22 [00:00<00:10,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp/fail1_episode3_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:   9%|▉         | 2/22 [00:01<00:10,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp/fail1_episode2_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  14%|█▎        | 3/22 [00:01<00:09,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp/fail1_episode4_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  18%|█▊        | 4/22 [00:02<00:11,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case1_missingGrasp/fail1_episode1_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  23%|██▎       | 5/22 [00:03<00:11,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case4_release/fail4_episode2_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  27%|██▋       | 6/22 [00:03<00:11,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case4_release/fail4_episode4_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  32%|███▏      | 7/22 [00:04<00:09,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case4_release/fail4_episode1_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  36%|███▋      | 8/22 [00:04<00:08,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case4_release/fail4_episode5_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  41%|████      | 9/22 [00:05<00:07,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case4_release/fail4_episode3_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  45%|████▌     | 10/22 [00:06<00:07,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp/fail2_episode4_step349_noise30\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  50%|█████     | 11/22 [00:07<00:07,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp/fail2_episode1_step349_noise30\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  55%|█████▍    | 12/22 [00:07<00:07,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp/fail2_episode5_step349_noise30\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  59%|█████▉    | 13/22 [00:08<00:05,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp/fail2_episode2_step349_noise30\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  64%|██████▎   | 14/22 [00:08<00:04,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case2_outofcontrolPregrasp/fail2_episode3_step349_noise30\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  68%|██████▊   | 15/22 [00:09<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin/fail3_episode5_step349_noise200\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  73%|███████▎  | 16/22 [00:09<00:03,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin/fail3_episode4_step349_noise200\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  77%|███████▋  | 17/22 [00:10<00:02,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin/fail3_episode3_step349_noise200\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  82%|████████▏ | 18/22 [00:10<00:02,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin/fail3_episode1_step349_noise200\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  86%|████████▋ | 19/22 [00:11<00:01,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case3_outofcontrolMovetobin/fail3_episode2_step349_noise200\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  91%|█████████ | 20/22 [00:12<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case5_light/fail5_episode5_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes:  95%|█████████▌| 21/22 [00:12<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing episode: /AILAB-summer-school-2025/fail_data_raw/fail_case5_light/fail5_episode4_step349\n",
      "[INFO] Robot state shape: (70, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing episodes: 100%|██████████| 22/22 [00:13<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fitting PCA models...\n",
      "[INFO] Detected state_dim = 7\n",
      "[INFO] front view PCA variance explained: 0.938\n",
      "[INFO] top view PCA variance explained: 0.944\n",
      "[INFO] wrist view PCA variance explained: 0.935\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case1_missingGrasp_failtype1_episode5_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case1_missingGrasp_failtype1_episode3_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case1_missingGrasp_failtype1_episode2_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case1_missingGrasp_failtype1_episode4_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case1_missingGrasp_failtype1_episode1_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case4_release_failtype4_episode2_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case4_release_failtype4_episode4_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case4_release_failtype4_episode1_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case4_release_failtype4_episode5_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case4_release_failtype4_episode3_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case2_outofcontrolPregrasp_failtype2_episode4_step349_noise30.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case2_outofcontrolPregrasp_failtype2_episode1_step349_noise30.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case2_outofcontrolPregrasp_failtype2_episode5_step349_noise30.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case2_outofcontrolPregrasp_failtype2_episode2_step349_noise30.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case2_outofcontrolPregrasp_failtype2_episode3_step349_noise30.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case3_outofcontrolMovetobin_failtype3_episode5_step349_noise200.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case3_outofcontrolMovetobin_failtype3_episode4_step349_noise200.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case3_outofcontrolMovetobin_failtype3_episode3_step349_noise200.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case3_outofcontrolMovetobin_failtype3_episode1_step349_noise200.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case3_outofcontrolMovetobin_failtype3_episode2_step349_noise200.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case5_light_failtype5_episode5_step349.npz\n",
      "[INFO] Saved compressed episode: compressed_episodes/fail_case5_light_failtype5_episode4_step349.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# success case \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "@dataclass\n",
    "class ImageOnlyConfig:\n",
    "    \"\"\"Configuration for image-only processing\"\"\"\n",
    "    \n",
    "    # ===== PATHS =====\n",
    "    IMAGE_FOLDER: str = \"success_traj_img\"\n",
    "    \n",
    "    OUTPUT_PATH: str = \"image_features.npz\"\n",
    "    PCA_MODEL_PATH: str = \"image_pca_models.pkl\"\n",
    "    \n",
    "    # ===== IMAGE PROCESSING =====\n",
    "    RESNET_FEATURE_DIM: int = 512  # ResNet18 final layer per view\n",
    "    VIEWS: List[str] = None\n",
    "    \n",
    "    # ===== PCA COMPRESSION =====\n",
    "    COMPRESSED_DIM: int = 64  # Final compressed dimension per view\n",
    "    TOTAL_COMPRESSED_DIM: int = 192  # 64 * 3 views\n",
    "    \n",
    "    # ===== MODEL =====\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE: int = 32\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.VIEWS is None:\n",
    "            self.VIEWS = [\"front\", \"top\", \"wrist\"]\n",
    "        \n",
    "        print(f\"Image-Only Processor Config\")\n",
    "        print(f\"Views: {self.VIEWS}\")\n",
    "        print(f\"ResNet Features: {self.RESNET_FEATURE_DIM} per view\")\n",
    "        print(f\"Compressed Features: {self.COMPRESSED_DIM} per view\")\n",
    "        print(f\"Total Compressed: {self.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"Device: {self.DEVICE}\")\n",
    "\n",
    "class EpisodeProcessor:\n",
    "    def __init__(self, config: ImageOnlyConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.DEVICE)\n",
    "\n",
    "        # ResNet18 feature extractor\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.pca_models = {}\n",
    "        print(f\"[INFO] ResNet18 feature extractor initialized on {self.device}\")\n",
    "\n",
    "    def extract_features(self, image_path: str) -> np.ndarray:\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                features = self.model(image_tensor).view(1, -1)\n",
    "            return features.cpu().numpy().flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to process {image_path}: {e}\")\n",
    "            return np.zeros(self.config.RESNET_FEATURE_DIM)\n",
    "\n",
    "    def process_episode(self, episode_dir: str) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Process a single episode directory\"\"\"\n",
    "        print(f\"[INFO] Processing episode: {episode_dir}\")\n",
    "        \n",
    "        # Load robot state\n",
    "        state_path = os.path.join(episode_dir, \"robot_state.npz\")\n",
    "        if not os.path.exists(state_path):\n",
    "            raise FileNotFoundError(f\"No robot_state.npz found in {episode_dir}\")\n",
    "        state_data = np.load(state_path)\n",
    "        state_key = list(state_data.keys())[0]  \n",
    "        robot_states = state_data[state_key]\n",
    "        print(f\"[INFO] Robot state shape: {robot_states.shape}\")\n",
    "\n",
    "        # Build timestep list\n",
    "        front_dir = os.path.join(episode_dir, \"front_view\")\n",
    "        timesteps = sorted([\n",
    "            int(f.split('_')[-1].replace('.png', ''))\n",
    "            for f in os.listdir(front_dir) if f.endswith('.png')\n",
    "        ])\n",
    "\n",
    "        features = []\n",
    "        for i, ts in enumerate(timesteps):\n",
    "            view_feats = []\n",
    "            for view in self.config.VIEWS:\n",
    "                img_path = os.path.join(episode_dir, f\"{view}_view\", f\"{view}_view_{ts}.png\")\n",
    "                feat = self.extract_features(img_path)\n",
    "                view_feats.append(feat)\n",
    "\n",
    "            combined_img_feat = np.concatenate(view_feats)  # [1536]\n",
    "            features.append(np.concatenate([combined_img_feat, robot_states[i]]))\n",
    "\n",
    "        return {\"observation\": np.vstack(features)}\n",
    "\n",
    "    def fit_pca(self, all_episode_features: List[np.ndarray]):\n",
    "        \"\"\"Fit PCA per view across all episodes\"\"\"\n",
    "        print(\"[INFO] Fitting PCA models...\")\n",
    "\n",
    "        total_img_dim = len(self.config.VIEWS) * self.config.RESNET_FEATURE_DIM\n",
    "        sample_feat = all_episode_features[0]\n",
    "        state_dim = sample_feat.shape[1] - total_img_dim\n",
    "        print(f\"[INFO] Detected state_dim = {state_dim}\")\n",
    "\n",
    "        view_features = {view: [] for view in self.config.VIEWS}\n",
    "\n",
    "        for episode_feat in all_episode_features:\n",
    "            img_feats = episode_feat[:, :-state_dim]\n",
    "            for i, view in enumerate(self.config.VIEWS):\n",
    "                start, end = i * self.config.RESNET_FEATURE_DIM, (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                view_features[view].append(img_feats[:, start:end])\n",
    "\n",
    "        for view in self.config.VIEWS:\n",
    "            X = np.vstack(view_features[view])  # (N*T, 512)\n",
    "            pca = PCA(n_components=self.config.COMPRESSED_DIM)\n",
    "            pca.fit(X)\n",
    "            self.pca_models[view] = pca\n",
    "            print(f\"[INFO] {view} view PCA variance explained: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "    def compress_episode(self, episode_dict: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Apply PCA compression to images, concat state as-is\"\"\"\n",
    "        obs = episode_dict[\"observation\"]\n",
    "        total_img_dim = len(self.config.VIEWS) * self.config.RESNET_FEATURE_DIM\n",
    "        state_dim = obs.shape[1] - total_img_dim\n",
    "\n",
    "        img_feats, state_feats = obs[:, :-state_dim], obs[:, -state_dim:]\n",
    "\n",
    "        compressed_features = []\n",
    "        for row in img_feats:\n",
    "            comp_views = []\n",
    "            for i, view in enumerate(self.config.VIEWS):\n",
    "                start, end = i*self.config.RESNET_FEATURE_DIM, (i+1)*self.config.RESNET_FEATURE_DIM\n",
    "                view_feat = row[start:end].reshape(1, -1)\n",
    "                comp_views.append(self.pca_models[view].transform(view_feat).flatten())\n",
    "            compressed_features.append(np.concatenate(comp_views))\n",
    "\n",
    "        compressed_features = np.vstack(compressed_features)\n",
    "        final_obs = np.hstack([compressed_features, state_feats])  # PCA된 이미지 + 원본 state\n",
    "        return {\"observation\": final_obs}\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def format_episode_name(epi_dir: str) -> str:\n",
    "    parts = epi_dir.split(os.sep)\n",
    "    base = parts[-1]       \n",
    "    parent = parts[-2] if len(parts) >= 2 else \"\"\n",
    "\n",
    "    if parent.startswith(\"fail_case\"):\n",
    "        failtype_num = ''.join([c for c in parent if c.isdigit()])\n",
    "        new_base = base.replace(f\"fail{failtype_num}_\", f\"failtype{failtype_num}_\")\n",
    "        return f\"{new_base}\"\n",
    "    else:\n",
    "        return base  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = ImageOnlyConfig(\n",
    "        IMAGE_FOLDER=\"/AILAB-summer-school-2025/fail_data_raw\", # image path \n",
    "        OUTPUT_PATH=\"final_episode_dicts.npz\",\n",
    "        PCA_MODEL_PATH=\"/AILAB-summer-school-2025/success_data_preprocessing/pca_weight/image_pca_models.pkl\",\n",
    "        COMPRESSED_DIM=64)\n",
    "\n",
    "    processor = EpisodeProcessor(config)\n",
    "\n",
    "    # Step 1. 전체 episode 폴더 탐색 (success/fail 구분)\n",
    "    episode_dirs = []\n",
    "    for root in os.listdir(config.IMAGE_FOLDER):\n",
    "        root_path = os.path.join(config.IMAGE_FOLDER, root)\n",
    "        if not os.path.isdir(root_path):\n",
    "            continue\n",
    "\n",
    "        if root.startswith(\"success_\"):  \n",
    "            episode_dirs.append(root_path)\n",
    "        elif root.startswith(\"fail_case\"):\n",
    "            for sub in os.listdir(root_path):\n",
    "                sub_path = os.path.join(root_path, sub)\n",
    "                if os.path.isdir(sub_path) and sub.startswith(\"fail\"):\n",
    "                    episode_dirs.append(sub_path)\n",
    "\n",
    "    print(f\"[INFO] Found {len(episode_dirs)} episodes.\")\n",
    "\n",
    "    # Step 2. 각 episode feature 추출\n",
    "    all_episode_features = []\n",
    "    raw_episode_dicts = {}\n",
    "    for epi_dir in tqdm(episode_dirs, desc=\"Processing episodes\"):\n",
    "        try:\n",
    "            epi_name = format_episode_name(epi_dir)\n",
    "            episode_dict = processor.process_episode(epi_dir)\n",
    "            raw_episode_dicts[epi_name] = episode_dict\n",
    "            all_episode_features.append(episode_dict[\"observation\"])\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipping {epi_dir}: {e}\")\n",
    "\n",
    "    # Step 3. PCA 학습 (view별)\n",
    "    processor.fit_pca(all_episode_features)\n",
    "\n",
    "    # Step 4. PCA 압축 적용 및 저장\n",
    "    output_dir = \"compressed_episodes\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for epi_name, epi_dict in raw_episode_dicts.items():\n",
    "        compressed_dict = processor.compress_episode(epi_dict)\n",
    "        epi_name = epi_name.replace(\"/\", \"_\")\n",
    "        save_path = os.path.join(output_dir, f\"{epi_name}.npz\")\n",
    "        np.savez_compressed(save_path, **compressed_dict)\n",
    "        print(f\"[INFO] Saved compressed episode: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Key: img\n",
    "#   Shape: (97, 16)\n",
    "#   Dtype: float32\n",
    "#   Sample (first element):\n",
    "# [-0.5854379   1.6493505  -1.0049931  -0.21947424 -0.70256466 -0.39046937\n",
    "#  -0.4245706  -0.36956656  0.24001157 -0.14053325]\n",
    "# ------------------------------------------------------------\n",
    "# Key: robot_state\n",
    "#   Shape: (97, 9)\n",
    "#   Dtype: float32\n",
    "#   Sample (first element):\n",
    "# [ 4.6333355e-01  5.1339157e-08  3.8548785e-01  8.6034834e-03\n",
    "#   9.2161107e-01  2.0462854e-02  3.8747975e-01 -3.5621226e-05\n",
    "#   0.0000000e+00  3.0250198e-01]\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ----- Image feature extractor -----\n",
    "def get_image_feature(image_path, model, transform, device=\"cpu\"):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.squeeze().cpu().numpy()\n",
    "\n",
    "# ----- Main processing function -----\n",
    "def process_success_traj(base_dir, output_dir, view=\"top\"):\n",
    "    \"\"\"\n",
    "    base_dir: success_traj root directory (/AILAB-summer-school-2025/success_traj/)\n",
    "    output_dir: where to save merged dicts\n",
    "    view: \"front\", \"top\", or \"wrist\"\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Pretrained ResNet18 -> 16D feature\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    num_ftrs = resnet18.fc.in_features\n",
    "    resnet18.fc = nn.Linear(num_ftrs, 16)\n",
    "    resnet18 = resnet18.to(device)\n",
    "    resnet18.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Traverse all traj folders\n",
    "    for traj_folder in sorted(os.listdir(base_dir)):\n",
    "        traj_path = os.path.join(base_dir, traj_folder)\n",
    "        if not os.path.isdir(traj_path) or not traj_folder.startswith(\"simulation_traj_\"):\n",
    "            continue\n",
    "\n",
    "        traj_num = traj_folder.split(\"_\")[2]\n",
    "        dict_name = f\"success_traj_{traj_num}_{view}\"\n",
    "\n",
    "        # Collect image features\n",
    "        img_features = []\n",
    "        for filename in sorted(os.listdir(traj_path)):\n",
    "            if filename.startswith(f\"{view}_view\") and filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(traj_path, filename)\n",
    "                feat = get_image_feature(image_path, resnet18, transform, device)\n",
    "                img_features.append(feat)\n",
    "\n",
    "        img_features = np.stack(img_features, axis=0)  # shape: [num_images, feature_dim]\n",
    "\n",
    "        # Collect robot states from all timestep npz\n",
    "        all_states = []\n",
    "        for file in sorted(os.listdir(traj_path)):\n",
    "            if file.endswith(\".npz\") and file.startswith(\"states_\"):\n",
    "                file_path = os.path.join(traj_path, file)\n",
    "                data = np.load(file_path)\n",
    "                for key in data.files:\n",
    "                    all_states.append(data[key])\n",
    "\n",
    "        robot_states = np.concatenate(all_states, axis=0)\n",
    "\n",
    "        # Build dict\n",
    "        traj_dict = {\n",
    "            \"img\": img_features,\n",
    "            \"robot_state\": robot_states\n",
    "        }\n",
    "\n",
    "        # Save npz\n",
    "        save_path = os.path.join(output_dir, f\"{dict_name}.npz\")\n",
    "        np.savez(save_path, **traj_dict)\n",
    "\n",
    "        print(f\"[Saved] {save_path}: img {img_features.shape}, state {robot_states.shape}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/AILAB-summer-school-2025/success_traj/\"\n",
    "    output_dir = \"/AILAB-summer-school-2025/success_traj_comp/\"\n",
    "    process_success_traj(base_dir, output_dir, view=\"wrist\")  # front/top/wrist 중 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6db53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_npz(file_path):\n",
    "    \"\"\"\n",
    "    Inspect contents of a .npz file: keys, shapes, and dtypes\n",
    "    \"\"\"\n",
    "    data = np.load(file_path)\n",
    "    print(f\"Inspecting {file_path}\")\n",
    "    print(\"-\" * 60)\n",
    "    for key in data.files:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"  Shape: {data[key].shape}\")\n",
    "        print(f\"  Dtype: {data[key].dtype}\")\n",
    "        print(f\"  Sample (first element):\\n{data[key].flatten()[:10]}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"/AILAB-summer-school-2025/success_traj/success_traj_comp_front/success_traj_2_front.npz\"\n",
    "    inspect_npz(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success case \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "@dataclass\n",
    "class ImageOnlyConfig:\n",
    "    \"\"\"Configuration for image-only processing\"\"\"\n",
    "    \n",
    "    # ===== PATHS =====\n",
    "    IMAGE_FOLDER: str = \"success_traj_img\"\n",
    "    \n",
    "    OUTPUT_PATH: str = \"image_features.npz\"\n",
    "    PCA_MODEL_PATH: str = \"image_pca_models.pkl\"\n",
    "    \n",
    "    # ===== IMAGE PROCESSING =====\n",
    "    RESNET_FEATURE_DIM: int = 512  # ResNet18 final layer per view\n",
    "    VIEWS: List[str] = None\n",
    "    \n",
    "    # ===== PCA COMPRESSION =====\n",
    "    COMPRESSED_DIM: int = 64  # Final compressed dimension per view\n",
    "    TOTAL_COMPRESSED_DIM: int = 192  # 64 * 3 views\n",
    "    \n",
    "    # ===== MODEL =====\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE: int = 32\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.VIEWS is None:\n",
    "            self.VIEWS = [\"front\", \"top\", \"wrist\"]\n",
    "        \n",
    "        print(f\"Image-Only Processor Config\")\n",
    "        print(f\"Views: {self.VIEWS}\")\n",
    "        print(f\"ResNet Features: {self.RESNET_FEATURE_DIM} per view\")\n",
    "        print(f\"Compressed Features: {self.COMPRESSED_DIM} per view\")\n",
    "        print(f\"Total Compressed: {self.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"Device: {self.DEVICE}\")\n",
    "\n",
    "class ImageOnlyProcessor:\n",
    "    \"\"\"Process only images to create latent vectors\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ImageOnlyConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.DEVICE)\n",
    "\n",
    "        # Initialize ResNet18\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])  # Remove classifier\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Image preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Storage\n",
    "        self.image_index = {}\n",
    "        self.pca_models = {}\n",
    "        \n",
    "        print(f\"ResNet18 feature extractor initialized\")\n",
    "    \n",
    "    def parse_filename(self, filename: str) -> Optional[Tuple[str, str, int]]:\n",
    "        \"\"\"Parse image filename: traj_key, view, timestep\"\"\"\n",
    "        name = filename.replace('.png', '')\n",
    "        parts = name.split('_')\n",
    "        \n",
    "        try:\n",
    "            # Find view\n",
    "            view = None\n",
    "            view_idx = -1\n",
    "            for i, part in enumerate(parts):\n",
    "                if part in self.config.VIEWS:\n",
    "                    view = part\n",
    "                    view_idx = i\n",
    "                    break\n",
    "            \n",
    "            if view is None:\n",
    "                return None\n",
    "            \n",
    "            # Extract trajectory key and timestep\n",
    "            traj_key = '_'.join(parts[:view_idx])\n",
    "            timestep = int(parts[-1])\n",
    "            \n",
    "            return traj_key, view, timestep\n",
    "            \n",
    "        except (ValueError, IndexError):\n",
    "            return None\n",
    "    \n",
    "    def build_image_index(self):\n",
    "        print(f\"Building image index from: {self.config.IMAGE_FOLDER}\")\n",
    "        image_index = defaultdict(lambda: defaultdict(dict))\n",
    "        total_images, parsed_images = 0, 0\n",
    "\n",
    "        for root, _, files in os.walk(self.config.IMAGE_FOLDER):\n",
    "            for filename in files:\n",
    "                if not filename.endswith('.png'):\n",
    "                    continue\n",
    "                total_images += 1\n",
    "                parse_result = self.parse_filename(filename)\n",
    "                if parse_result:\n",
    "                    traj_key, view, timestep = parse_result\n",
    "                    image_path = os.path.join(root, filename)\n",
    "                    image_index[traj_key][timestep][view] = image_path\n",
    "                    parsed_images += 1\n",
    "\n",
    "        complete_triplets = sum(\n",
    "            len(image_index[traj][ts]) == len(self.config.VIEWS)\n",
    "            for traj in image_index for ts in image_index[traj]\n",
    "        )\n",
    "\n",
    "        print(f\"Total images: {total_images}, Parsed: {parsed_images}, Complete triplets: {complete_triplets}\")\n",
    "        self.image_index = dict(image_index)\n",
    "        return complete_triplets\n",
    "    \n",
    "    def extract_features(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Extract ResNet18 features from single image\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = self.model(image_tensor)\n",
    "                features = features.view(features.size(0), -1)\n",
    "            \n",
    "            return features.cpu().numpy().flatten()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return np.zeros(self.config.RESNET_FEATURE_DIM)\n",
    "    \n",
    "    def extract_all_image_features(self) -> Dict[str, Dict[int, np.ndarray]]:\n",
    "        \"\"\"Extract features for all complete image triplets\"\"\"\n",
    "        print(\"Extracting multiview image features...\")\n",
    "        \n",
    "        features_dict = {}\n",
    "        total_processed = 0\n",
    "        \n",
    "        for traj_key in tqdm(self.image_index, desc=\"Processing trajectories\"):\n",
    "            features_dict[traj_key] = {}\n",
    "            \n",
    "            for timestep in self.image_index[traj_key]:\n",
    "                # Check if all views available\n",
    "                available_views = set(self.image_index[traj_key][timestep].keys())\n",
    "                required_views = set(self.config.VIEWS)\n",
    "                \n",
    "                if available_views == required_views:\n",
    "                    # Extract features from all 3 views\n",
    "                    view_features = []\n",
    "                    \n",
    "                    for view in self.config.VIEWS:\n",
    "                        image_path = self.image_index[traj_key][timestep][view]\n",
    "                        features = self.extract_features(image_path)\n",
    "                        view_features.append(features)\n",
    "                    \n",
    "                    # Concatenate all view features\n",
    "                    combined_features = np.concatenate(view_features)  # [1536,]\n",
    "                    features_dict[traj_key][timestep] = combined_features\n",
    "                    total_processed += 1\n",
    "        \n",
    "        print(f\"Extracted features for {total_processed} complete image triplets\")\n",
    "        return features_dict\n",
    "    \n",
    "    def fit_pca_models(self, features_dict: Dict) -> Dict[str, PCA]:\n",
    "        \"\"\"Fit PCA for each view separately\"\"\"\n",
    "        print(\"Fitting PCA compression models...\")\n",
    "        \n",
    "        # Collect features by view\n",
    "        view_features = {view: [] for view in self.config.VIEWS}\n",
    "        \n",
    "        for traj_key in features_dict:\n",
    "            for timestep in features_dict[traj_key]:\n",
    "                combined_features = features_dict[traj_key][timestep]\n",
    "                \n",
    "                # Split by view\n",
    "                for i, view in enumerate(self.config.VIEWS):\n",
    "                    start_idx = i * self.config.RESNET_FEATURE_DIM\n",
    "                    end_idx = (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                    view_feature = combined_features[start_idx:end_idx]\n",
    "                    view_features[view].append(view_feature)\n",
    "        \n",
    "        # Fit PCA for each view\n",
    "        pca_models = {}\n",
    "        for view in self.config.VIEWS:\n",
    "            if view_features[view]:\n",
    "                features_array = np.array(view_features[view])\n",
    "                \n",
    "                pca = PCA(n_components=self.config.COMPRESSED_DIM)\n",
    "                pca.fit(features_array)\n",
    "                \n",
    "                explained_var = pca.explained_variance_ratio_.sum()\n",
    "                print(f\"  {view} view: {explained_var:.3f} variance explained\")\n",
    "                \n",
    "                pca_models[view] = pca\n",
    "        \n",
    "        self.pca_models = pca_models\n",
    "        return pca_models\n",
    "    \n",
    "    def compress_all_features(self, features_dict: Dict) -> Dict[str, Dict[int, np.ndarray]]:\n",
    "        \"\"\"Apply PCA compression to all features\"\"\"\n",
    "        print(\"Compressing features with PCA...\")\n",
    "        \n",
    "        compressed_dict = {}\n",
    "        \n",
    "        for traj_key in tqdm(features_dict, desc=\"Compressing\"):\n",
    "            compressed_dict[traj_key] = {}\n",
    "            \n",
    "            for timestep in features_dict[traj_key]:\n",
    "                combined_features = features_dict[traj_key][timestep]\n",
    "                \n",
    "                # Compress each view separately\n",
    "                compressed_views = []\n",
    "                for i, view in enumerate(self.config.VIEWS):\n",
    "                    start_idx = i * self.config.RESNET_FEATURE_DIM\n",
    "                    end_idx = (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                    view_feature = combined_features[start_idx:end_idx]\n",
    "                    \n",
    "                    if view in self.pca_models:\n",
    "                        compressed_feature = self.pca_models[view].transform([view_feature])\n",
    "                        compressed_views.append(compressed_feature.flatten())\n",
    "                    else:\n",
    "                        compressed_views.append(np.zeros(self.config.COMPRESSED_DIM))\n",
    "                \n",
    "                # Combine compressed features from all views\n",
    "                final_compressed = np.concatenate(compressed_views)  # [192,]\n",
    "                compressed_dict[traj_key][timestep] = final_compressed\n",
    "        \n",
    "        return compressed_dict\n",
    "    \n",
    "    def save_image_features(self, compressed_features: Dict):\n",
    "        \"\"\"Save image features only\"\"\"\n",
    "        print(f\"Saving image features to: {self.config.OUTPUT_PATH}\")\n",
    "        \n",
    "        # Convert to arrays with metadata\n",
    "        feature_list = []\n",
    "        metadata_list = []\n",
    "        \n",
    "        for traj_key in compressed_features:\n",
    "            for timestep in compressed_features[traj_key]:\n",
    "                feature_vector = compressed_features[traj_key][timestep]\n",
    "                feature_list.append(feature_vector)\n",
    "                \n",
    "                metadata_list.append({\n",
    "                    'traj_key': traj_key,\n",
    "                    'timestep': timestep,\n",
    "                    'feature_dim': len(feature_vector)\n",
    "                })\n",
    "        \n",
    "        feature_array = np.array(feature_list)\n",
    "        \n",
    "        # Save features\n",
    "        np.savez_compressed(\n",
    "            self.config.OUTPUT_PATH,\n",
    "            features=feature_array,\n",
    "            metadata=metadata_list,\n",
    "            config=self.config.__dict__\n",
    "        )\n",
    "        \n",
    "        # Save PCA models\n",
    "        with open(self.config.PCA_MODEL_PATH, 'wb') as f:\n",
    "            pickle.dump(self.pca_models, f)\n",
    "        \n",
    "        print(f\"Image features saved:\")\n",
    "        print(f\"  Features: {self.config.OUTPUT_PATH}\")\n",
    "        print(f\"  PCA models: {self.config.PCA_MODEL_PATH}\")\n",
    "        print(f\"  Total features: {len(feature_array)}\")\n",
    "        print(f\"  Feature dimension: {feature_array.shape[1]}\")\n",
    "        print(f\"  File size: {os.path.getsize(self.config.OUTPUT_PATH)/1024/1024:.1f} MB\")\n",
    "\n",
    "def process_images_only(config: ImageOnlyConfig = None) -> str:\n",
    "    \"\"\"\n",
    "    Main function to process images only\n",
    "    \n",
    "    Returns:\n",
    "        Path to generated image features file\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = ImageOnlyConfig()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Image-Only Processing Pipeline\")\n",
    "    print(\"Extracting latent vectors from multiview images\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Initialize processor\n",
    "        processor = ImageOnlyProcessor(config)\n",
    "        \n",
    "        # Step 1: Build image index\n",
    "        print(\"\\n1. Building image index...\")\n",
    "        complete_count = processor.build_image_index()\n",
    "        \n",
    "        if complete_count == 0:\n",
    "            raise ValueError(\"No complete image triplets found!\")\n",
    "        \n",
    "        # Step 2: Extract raw features\n",
    "        print(\"\\n2. Extracting ResNet18 features...\")\n",
    "        features_dict = processor.extract_all_image_features()\n",
    "        \n",
    "        # Step 3: Fit PCA\n",
    "        print(\"\\n3. Fitting PCA compression...\")\n",
    "        processor.fit_pca_models(features_dict)\n",
    "        \n",
    "        # Step 4: Compress features\n",
    "        print(\"\\n4. Compressing features...\")\n",
    "        compressed_features = processor.compress_all_features(features_dict)\n",
    "        \n",
    "        # Step 5: Save results\n",
    "        print(\"\\n5. Saving image features...\")\n",
    "        processor.save_image_features(compressed_features)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Image-Only Processing Completed Successfully!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"✅ Generated: {config.OUTPUT_PATH}\")\n",
    "        print(f\"✅ Feature dimension: {config.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"✅ Views processed: {config.VIEWS}\")\n",
    "        \n",
    "        return config.OUTPUT_PATH\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Processing failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = ImageOnlyConfig()\n",
    "    output_path = process_images_only(config)\n",
    "    print(f\"\\nImage latent vectors ready: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# failure case\n",
    "\n",
    "import os, pickle, numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "\n",
    "class MultiViewConfig:\n",
    "    IMAGE_ROOT: str = \"/AILAB-summer-school-2025/failure_case/failcase2\"\n",
    "    OUTPUT_ROOT: str = \"/AILAB-summer-school-2025/failure_case_comp/failcase2\"\n",
    "    VIEWS: dict = {\"front_view\": \"front\", \"top_view\": \"top\", \"wrist_view\": \"wrist\"}\n",
    "    RESNET_FEATURE_DIM: int = 512\n",
    "    COMPRESSED_DIM: int = 64\n",
    "    TOTAL_COMPRESSED_DIM: int = 64 * 3\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class MultiViewProcessor:\n",
    "    def __init__(self, config: MultiViewConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.DEVICE)\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        self.model.to(self.device).eval()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                 std=[0.229,0.224,0.225])\n",
    "        ])\n",
    "        self.pca_models = {}\n",
    "        print(\"Initialized ResNet18 for multiview\")\n",
    "\n",
    "    def extract_feature(self, image_path: str) -> np.ndarray:\n",
    "        try:\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "            x = self.transform(img).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                feat = self.model(x).view(1,-1)\n",
    "            return feat.cpu().numpy().flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return np.zeros(self.config.RESNET_FEATURE_DIM)\n",
    "\n",
    "    def parse_filename(self, filename: str):\n",
    "        if not filename.endswith(\".png\"):\n",
    "            return None\n",
    "        name = filename.replace(\".png\", \"\")\n",
    "        # view 매칭\n",
    "        view = None\n",
    "        for candidate in [\"front_view\", \"top_view\", \"wrist_view\"]:\n",
    "            if candidate in name:\n",
    "                view = candidate.replace(\"_view\", \"\")\n",
    "                break\n",
    "        if view is None:\n",
    "            return None\n",
    "        try:\n",
    "            timestep = int(name.split(\"_\")[-1])\n",
    "        except ValueError:\n",
    "            return None\n",
    "        traj_key = name.rsplit(f\"_{view}_\", 1)[0]\n",
    "        return traj_key, view, timestep\n",
    "\n",
    "    def fit_pca_models(self, feats: np.ndarray):\n",
    "        \"\"\"fit PCA per view from stacked feats\"\"\"\n",
    "        pca_models, reduced_views = {}, []\n",
    "        for i, view in enumerate([\"front\",\"top\",\"wrist\"]):\n",
    "            view_data = feats[:, i*512:(i+1)*512]\n",
    "            pca = PCA(n_components=self.config.COMPRESSED_DIM)\n",
    "            pca.fit(view_data)\n",
    "            explained = pca.explained_variance_ratio_.sum()\n",
    "            print(f\"  PCA fitted for {view}: explains {explained:.3f}\")\n",
    "            pca_models[view] = pca\n",
    "        self.pca_models = pca_models\n",
    "        return pca_models\n",
    "\n",
    "    def process_traj(self, traj_dir):\n",
    "        print(f\"\\nProcessing {traj_dir}\")\n",
    "\n",
    "        traj_name = os.path.basename(traj_dir)\n",
    "        # output trajectory dir\n",
    "        out_traj_dir = os.path.join(self.config.OUTPUT_ROOT, traj_name)\n",
    "        img_out = os.path.join(out_traj_dir, \"img\")\n",
    "        state_out = os.path.join(out_traj_dir, \"robot_state\")\n",
    "        os.makedirs(img_out, exist_ok=True)\n",
    "        os.makedirs(state_out, exist_ok=True)\n",
    "\n",
    "        image_index = defaultdict(dict)\n",
    "        for fname in os.listdir(traj_dir):\n",
    "            res = self.parse_filename(fname)\n",
    "            if res:\n",
    "                traj_key, view, ts = res\n",
    "                image_index[ts][view] = os.path.join(traj_dir, fname)\n",
    "\n",
    "        timesteps = [t for t in image_index if len(image_index[t]) == 3]\n",
    "        if not timesteps:\n",
    "            print(\"  No complete triplets found\")\n",
    "            return\n",
    "        timesteps = sorted(timesteps)\n",
    "\n",
    "        # 이미지 feature 추출\n",
    "        feats = []\n",
    "        for t in timesteps:\n",
    "            view_feats = []\n",
    "            for view in [\"front\",\"top\",\"wrist\"]:\n",
    "                feat = self.extract_feature(image_index[t][view])\n",
    "                view_feats.append(feat)\n",
    "            feats.append(np.concatenate(view_feats))\n",
    "        feats = np.array(feats)\n",
    "\n",
    "        # PCA transform (fit if first traj)\n",
    "        if not self.pca_models:\n",
    "            print(\"  Fitting PCA models...\")\n",
    "            self.fit_pca_models(feats)\n",
    "\n",
    "        reduced_views = []\n",
    "        for i, view in enumerate([\"front\",\"top\",\"wrist\"]):\n",
    "            view_data = feats[:, i*512:(i+1)*512]\n",
    "            reduced = self.pca_models[view].transform(view_data)\n",
    "            reduced_views.append(reduced)\n",
    "        final_feats = np.concatenate(reduced_views, axis=1)\n",
    "\n",
    "        feat_dict = {t: final_feats[i] for i,t in enumerate(timesteps)}\n",
    "\n",
    "        # state npz 합치기\n",
    "        state_dict = {}\n",
    "        for fname in os.listdir(traj_dir):\n",
    "            if fname.endswith(\".npz\") and (fname.startswith(\"state_\") or fname.startswith(\"states_\")):\n",
    "                npz_path = os.path.join(traj_dir,fname)\n",
    "                try:\n",
    "                    ts = int(fname.split(\"_\")[-1].replace(\".npz\",\"\"))\n",
    "                except ValueError:\n",
    "                    print(f\"  ⚠️ Cannot parse timestep from {fname}\")\n",
    "                    continue\n",
    "\n",
    "                data = np.load(npz_path)\n",
    "                state_dict[ts] = {k: data[k] for k in data}\n",
    "\n",
    "        # 저장\n",
    "        with open(os.path.join(img_out,\"features.pkl\"),\"wb\") as f:\n",
    "            pickle.dump(feat_dict,f)\n",
    "\n",
    "        if state_dict:\n",
    "            np.savez_compressed(os.path.join(state_out,\"state.npz\"),\n",
    "                                **{f\"t{t}\": state_dict[t] for t in timesteps})\n",
    "        else:\n",
    "            print(\"  ⚠️ No robot state npz files found for this trajectory.\")\n",
    "\n",
    "        feature_array = np.array(list(feat_dict.values()))\n",
    "        print(f\"  저장 완료: {len(feature_array)} timesteps, feature dim {feature_array.shape[1]}\")\n",
    "\n",
    "        print(f\"Image features saved:\")\n",
    "        print(f\"  Features: {img_out}/features.pkl\")\n",
    "        print(f\"  Total timesteps: {len(feature_array)}\")\n",
    "        print(f\"  Feature dimension: {feature_array.shape[1]}\")\n",
    "\n",
    "def process_all(root_dir):\n",
    "    config = MultiViewConfig()\n",
    "    proc = MultiViewProcessor(config)\n",
    "    for traj in os.listdir(root_dir):\n",
    "        traj_dir = os.path.join(root_dir,traj)\n",
    "        if os.path.isdir(traj_dir):\n",
    "            proc.process_traj(traj_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all(\"/AILAB-summer-school-2025/failure_case/failcase2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
