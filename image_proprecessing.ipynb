{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-Only Processor Config\n",
      "Views: ['front', 'top', 'wrist']\n",
      "ResNet Features: 512 per view\n",
      "Compressed Features: 64 per view\n",
      "Total Compressed: 192\n",
      "Device: cuda\n",
      "============================================================\n",
      "Image-Only Processing Pipeline\n",
      "Extracting latent vectors from multiview images\n",
      "============================================================\n",
      "총 이미지: 0\n",
      "ResNet18 feature extractor initialized\n",
      "\n",
      "1. Building image index...\n",
      "Building image index from: success_traj_img\n",
      "Total images: 28654, Parsed: 28654, Complete triplets: 9551\n",
      "\n",
      "2. Extracting ResNet18 features...\n",
      "Extracting multiview image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trajectories:  62%|██████▏   | 61/98 [00:46<00:31,  1.17it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "@dataclass\n",
    "class ImageOnlyConfig:\n",
    "    \"\"\"Configuration for image-only processing\"\"\"\n",
    "    \n",
    "    # ===== PATHS =====\n",
    "    IMAGE_FOLDER: str = \"success_traj_img\"\n",
    "    \n",
    "    OUTPUT_PATH: str = \"image_features.npz\"\n",
    "    PCA_MODEL_PATH: str = \"image_pca_models.pkl\"\n",
    "    \n",
    "    # ===== IMAGE PROCESSING =====\n",
    "    RESNET_FEATURE_DIM: int = 512  # ResNet18 final layer per view\n",
    "    VIEWS: List[str] = None\n",
    "    \n",
    "    # ===== PCA COMPRESSION =====\n",
    "    COMPRESSED_DIM: int = 64  # Final compressed dimension per view\n",
    "    TOTAL_COMPRESSED_DIM: int = 192  # 64 * 3 views\n",
    "    \n",
    "    # ===== MODEL =====\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE: int = 32\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.VIEWS is None:\n",
    "            self.VIEWS = [\"front\", \"top\", \"wrist\"]\n",
    "        \n",
    "        print(f\"Image-Only Processor Config\")\n",
    "        print(f\"Views: {self.VIEWS}\")\n",
    "        print(f\"ResNet Features: {self.RESNET_FEATURE_DIM} per view\")\n",
    "        print(f\"Compressed Features: {self.COMPRESSED_DIM} per view\")\n",
    "        print(f\"Total Compressed: {self.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"Device: {self.DEVICE}\")\n",
    "\n",
    "class ImageOnlyProcessor:\n",
    "    \"\"\"Process only images to create latent vectors\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ImageOnlyConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.DEVICE)\n",
    "\n",
    "        # Initialize ResNet18\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])  # Remove classifier\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Image preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Storage\n",
    "        self.image_index = {}\n",
    "        self.pca_models = {}\n",
    "        \n",
    "        print(f\"ResNet18 feature extractor initialized\")\n",
    "    \n",
    "    def parse_filename(self, filename: str) -> Optional[Tuple[str, str, int]]:\n",
    "        \"\"\"Parse image filename: traj_key, view, timestep\"\"\"\n",
    "        name = filename.replace('.png', '')\n",
    "        parts = name.split('_')\n",
    "        \n",
    "        try:\n",
    "            # Find view\n",
    "            view = None\n",
    "            view_idx = -1\n",
    "            for i, part in enumerate(parts):\n",
    "                if part in self.config.VIEWS:\n",
    "                    view = part\n",
    "                    view_idx = i\n",
    "                    break\n",
    "            \n",
    "            if view is None:\n",
    "                return None\n",
    "            \n",
    "            # Extract trajectory key and timestep\n",
    "            traj_key = '_'.join(parts[:view_idx])\n",
    "            timestep = int(parts[-1])\n",
    "            \n",
    "            return traj_key, view, timestep\n",
    "            \n",
    "        except (ValueError, IndexError):\n",
    "            return None\n",
    "    \n",
    "    def build_image_index(self):\n",
    "        print(f\"Building image index from: {self.config.IMAGE_FOLDER}\")\n",
    "        image_index = defaultdict(lambda: defaultdict(dict))\n",
    "        total_images, parsed_images = 0, 0\n",
    "\n",
    "        for root, _, files in os.walk(self.config.IMAGE_FOLDER):\n",
    "            for filename in files:\n",
    "                if not filename.endswith('.png'):\n",
    "                    continue\n",
    "                total_images += 1\n",
    "                parse_result = self.parse_filename(filename)\n",
    "                if parse_result:\n",
    "                    traj_key, view, timestep = parse_result\n",
    "                    image_path = os.path.join(root, filename)\n",
    "                    image_index[traj_key][timestep][view] = image_path\n",
    "                    parsed_images += 1\n",
    "\n",
    "        complete_triplets = sum(\n",
    "            len(image_index[traj][ts]) == len(self.config.VIEWS)\n",
    "            for traj in image_index for ts in image_index[traj]\n",
    "        )\n",
    "\n",
    "        print(f\"Total images: {total_images}, Parsed: {parsed_images}, Complete triplets: {complete_triplets}\")\n",
    "        self.image_index = dict(image_index)\n",
    "        return complete_triplets\n",
    "    \n",
    "    def extract_features(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Extract ResNet18 features from single image\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = self.model(image_tensor)\n",
    "                features = features.view(features.size(0), -1)\n",
    "            \n",
    "            return features.cpu().numpy().flatten()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return np.zeros(self.config.RESNET_FEATURE_DIM)\n",
    "    \n",
    "    def extract_all_image_features(self) -> Dict[str, Dict[int, np.ndarray]]:\n",
    "        \"\"\"Extract features for all complete image triplets\"\"\"\n",
    "        print(\"Extracting multiview image features...\")\n",
    "        \n",
    "        features_dict = {}\n",
    "        total_processed = 0\n",
    "        \n",
    "        for traj_key in tqdm(self.image_index, desc=\"Processing trajectories\"):\n",
    "            features_dict[traj_key] = {}\n",
    "            \n",
    "            for timestep in self.image_index[traj_key]:\n",
    "                # Check if all views available\n",
    "                available_views = set(self.image_index[traj_key][timestep].keys())\n",
    "                required_views = set(self.config.VIEWS)\n",
    "                \n",
    "                if available_views == required_views:\n",
    "                    # Extract features from all 3 views\n",
    "                    view_features = []\n",
    "                    \n",
    "                    for view in self.config.VIEWS:\n",
    "                        image_path = self.image_index[traj_key][timestep][view]\n",
    "                        features = self.extract_features(image_path)\n",
    "                        view_features.append(features)\n",
    "                    \n",
    "                    # Concatenate all view features\n",
    "                    combined_features = np.concatenate(view_features)  # [1536,]\n",
    "                    features_dict[traj_key][timestep] = combined_features\n",
    "                    total_processed += 1\n",
    "        \n",
    "        print(f\"Extracted features for {total_processed} complete image triplets\")\n",
    "        return features_dict\n",
    "    \n",
    "    def fit_pca_models(self, features_dict: Dict) -> Dict[str, PCA]:\n",
    "        \"\"\"Fit PCA for each view separately\"\"\"\n",
    "        print(\"Fitting PCA compression models...\")\n",
    "        \n",
    "        # Collect features by view\n",
    "        view_features = {view: [] for view in self.config.VIEWS}\n",
    "        \n",
    "        for traj_key in features_dict:\n",
    "            for timestep in features_dict[traj_key]:\n",
    "                combined_features = features_dict[traj_key][timestep]\n",
    "                \n",
    "                # Split by view\n",
    "                for i, view in enumerate(self.config.VIEWS):\n",
    "                    start_idx = i * self.config.RESNET_FEATURE_DIM\n",
    "                    end_idx = (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                    view_feature = combined_features[start_idx:end_idx]\n",
    "                    view_features[view].append(view_feature)\n",
    "        \n",
    "        # Fit PCA for each view\n",
    "        pca_models = {}\n",
    "        for view in self.config.VIEWS:\n",
    "            if view_features[view]:\n",
    "                features_array = np.array(view_features[view])\n",
    "                \n",
    "                pca = PCA(n_components=self.config.COMPRESSED_DIM)\n",
    "                pca.fit(features_array)\n",
    "                \n",
    "                explained_var = pca.explained_variance_ratio_.sum()\n",
    "                print(f\"  {view} view: {explained_var:.3f} variance explained\")\n",
    "                \n",
    "                pca_models[view] = pca\n",
    "        \n",
    "        self.pca_models = pca_models\n",
    "        return pca_models\n",
    "    \n",
    "    def compress_all_features(self, features_dict: Dict) -> Dict[str, Dict[int, np.ndarray]]:\n",
    "        \"\"\"Apply PCA compression to all features\"\"\"\n",
    "        print(\"Compressing features with PCA...\")\n",
    "        \n",
    "        compressed_dict = {}\n",
    "        \n",
    "        for traj_key in tqdm(features_dict, desc=\"Compressing\"):\n",
    "            compressed_dict[traj_key] = {}\n",
    "            \n",
    "            for timestep in features_dict[traj_key]:\n",
    "                combined_features = features_dict[traj_key][timestep]\n",
    "                \n",
    "                # Compress each view separately\n",
    "                compressed_views = []\n",
    "                for i, view in enumerate(self.config.VIEWS):\n",
    "                    start_idx = i * self.config.RESNET_FEATURE_DIM\n",
    "                    end_idx = (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                    view_feature = combined_features[start_idx:end_idx]\n",
    "                    \n",
    "                    if view in self.pca_models:\n",
    "                        compressed_feature = self.pca_models[view].transform([view_feature])\n",
    "                        compressed_views.append(compressed_feature.flatten())\n",
    "                    else:\n",
    "                        compressed_views.append(np.zeros(self.config.COMPRESSED_DIM))\n",
    "                \n",
    "                # Combine compressed features from all views\n",
    "                final_compressed = np.concatenate(compressed_views)  # [192,]\n",
    "                compressed_dict[traj_key][timestep] = final_compressed\n",
    "        \n",
    "        return compressed_dict\n",
    "    \n",
    "    def save_image_features(self, compressed_features: Dict):\n",
    "        \"\"\"Save image features only\"\"\"\n",
    "        print(f\"Saving image features to: {self.config.OUTPUT_PATH}\")\n",
    "        \n",
    "        # Convert to arrays with metadata\n",
    "        feature_list = []\n",
    "        metadata_list = []\n",
    "        \n",
    "        for traj_key in compressed_features:\n",
    "            for timestep in compressed_features[traj_key]:\n",
    "                feature_vector = compressed_features[traj_key][timestep]\n",
    "                feature_list.append(feature_vector)\n",
    "                \n",
    "                metadata_list.append({\n",
    "                    'traj_key': traj_key,\n",
    "                    'timestep': timestep,\n",
    "                    'feature_dim': len(feature_vector)\n",
    "                })\n",
    "        \n",
    "        feature_array = np.array(feature_list)\n",
    "        \n",
    "        # Save features\n",
    "        np.savez_compressed(\n",
    "            self.config.OUTPUT_PATH,\n",
    "            features=feature_array,\n",
    "            metadata=metadata_list,\n",
    "            config=self.config.__dict__\n",
    "        )\n",
    "        \n",
    "        # Save PCA models\n",
    "        with open(self.config.PCA_MODEL_PATH, 'wb') as f:\n",
    "            pickle.dump(self.pca_models, f)\n",
    "        \n",
    "        print(f\"Image features saved:\")\n",
    "        print(f\"  Features: {self.config.OUTPUT_PATH}\")\n",
    "        print(f\"  PCA models: {self.config.PCA_MODEL_PATH}\")\n",
    "        print(f\"  Total features: {len(feature_array)}\")\n",
    "        print(f\"  Feature dimension: {feature_array.shape[1]}\")\n",
    "        print(f\"  File size: {os.path.getsize(self.config.OUTPUT_PATH)/1024/1024:.1f} MB\")\n",
    "\n",
    "def process_images_only(config: ImageOnlyConfig = None) -> str:\n",
    "    \"\"\"\n",
    "    Main function to process images only\n",
    "    \n",
    "    Returns:\n",
    "        Path to generated image features file\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = ImageOnlyConfig()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Image-Only Processing Pipeline\")\n",
    "    print(\"Extracting latent vectors from multiview images\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Initialize processor\n",
    "        processor = ImageOnlyProcessor(config)\n",
    "        \n",
    "        # Step 1: Build image index\n",
    "        print(\"\\n1. Building image index...\")\n",
    "        complete_count = processor.build_image_index()\n",
    "        \n",
    "        if complete_count == 0:\n",
    "            raise ValueError(\"No complete image triplets found!\")\n",
    "        \n",
    "        # Step 2: Extract raw features\n",
    "        print(\"\\n2. Extracting ResNet18 features...\")\n",
    "        features_dict = processor.extract_all_image_features()\n",
    "        \n",
    "        # Step 3: Fit PCA\n",
    "        print(\"\\n3. Fitting PCA compression...\")\n",
    "        processor.fit_pca_models(features_dict)\n",
    "        \n",
    "        # Step 4: Compress features\n",
    "        print(\"\\n4. Compressing features...\")\n",
    "        compressed_features = processor.compress_all_features(features_dict)\n",
    "        \n",
    "        # Step 5: Save results\n",
    "        print(\"\\n5. Saving image features...\")\n",
    "        processor.save_image_features(compressed_features)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Image-Only Processing Completed Successfully!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"✅ Generated: {config.OUTPUT_PATH}\")\n",
    "        print(f\"✅ Feature dimension: {config.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"✅ Views processed: {config.VIEWS}\")\n",
    "        \n",
    "        return config.OUTPUT_PATH\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Processing failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = ImageOnlyConfig()\n",
    "    output_path = process_images_only(config)\n",
    "    print(f\"\\nImage latent vectors ready: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
