{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase1_traj_0_wrist.npz: obs (139, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase1_traj_1_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase1_traj_2_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase1_traj_3_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase1_traj_4_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase2_traj_0_wrist.npz: obs (139, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase2_traj_1_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase2_traj_2_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase2_traj_3_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase2_traj_4_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase3_traj_0_wrist.npz: obs (139, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase3_traj_1_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase3_traj_2_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase3_traj_3_wrist.npz: obs (139, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase3_traj_4_wrist.npz: obs (139, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase4_traj_0_wrist.npz: obs (139, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase4_traj_1_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase4_traj_2_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase4_traj_3_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase4_traj_4_wrist.npz: obs (140, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase5_traj_0_wrist.npz: obs (91, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase5_traj_1_wrist.npz: obs (98, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase5_traj_2_wrist.npz: obs (98, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase5_traj_3_wrist.npz: obs (139, 25)\n",
      "[Saved] /AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/failcase5_traj_4_wrist.npz: obs (140, 25)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ----- Image feature extractor -----\n",
    "def get_image_feature(image_path, model, transform, device=\"cpu\"):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.squeeze().cpu().numpy()\n",
    "\n",
    "# ----- Failcase processing (concat to obs) -----\n",
    "def process_fail_traj(base_dir, output_dir, view=\"front\"):\n",
    "    \"\"\"\n",
    "    base_dir: /AILAB-summer-school-2025/failure_case/\n",
    "    output_dir: where to save merged npz dicts\n",
    "    view: \"front\", \"top\", or \"wrist\"\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Pretrained ResNet18 -> 16D feature\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    num_ftrs = resnet18.fc.in_features\n",
    "    resnet18.fc = nn.Linear(num_ftrs, 16)\n",
    "    resnet18 = resnet18.to(device)\n",
    "    resnet18.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Failcase 1~5 loop\n",
    "    for case_id in range(1, 6):\n",
    "        case_dir = os.path.join(base_dir, f\"failcase{case_id}\")\n",
    "        if not os.path.exists(case_dir):\n",
    "            continue\n",
    "\n",
    "        for traj_folder in sorted(os.listdir(case_dir)):\n",
    "            traj_path = os.path.join(case_dir, traj_folder)\n",
    "            if not os.path.isdir(traj_path) or not traj_folder.startswith(\"simulation_traj_\"):\n",
    "                continue\n",
    "\n",
    "            traj_num = traj_folder.split(\"_\")[2]\n",
    "            dict_name = f\"failcase{case_id}_traj_{traj_num}_{view}\"\n",
    "\n",
    "            # ---- Collect image features ----\n",
    "            img_features = []\n",
    "            for filename in sorted(os.listdir(traj_path)):\n",
    "                if filename.startswith(f\"{view}_view\") and filename.endswith(\".png\"):\n",
    "                    image_path = os.path.join(traj_path, filename)\n",
    "                    feat = get_image_feature(image_path, resnet18, transform, device)\n",
    "                    img_features.append(feat)\n",
    "\n",
    "            img_features = np.stack(img_features, axis=0).astype(np.float32)  # (T,16)\n",
    "\n",
    "            # ---- Collect robot states ----\n",
    "            all_states = []\n",
    "            for file in sorted(os.listdir(traj_path)):\n",
    "                if file.endswith(\".npz\") and file.startswith(\"states_\"):\n",
    "                    file_path = os.path.join(traj_path, file)\n",
    "                    data = np.load(file_path)\n",
    "                    for key in data.files:\n",
    "                        all_states.append(data[key])\n",
    "            robot_states = np.vstack(all_states).astype(np.float32)  # (T,9)\n",
    "\n",
    "            # ---- Concat to obs ----\n",
    "            obs = np.concatenate([robot_states, img_features], axis=-1)  # (T,25)\n",
    "\n",
    "            # ---- Save npz ----\n",
    "            save_path = os.path.join(output_dir, f\"{dict_name}.npz\")\n",
    "            np.savez(save_path, obs=obs)\n",
    "\n",
    "            print(f\"[Saved] {save_path}: obs {obs.shape}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/AILAB-summer-school-2025/failure_case/\"\n",
    "    output_dir = \"/AILAB-summer-school-2025/fail_traj_dict/fail_traj_comp_wrist/\"\n",
    "    process_fail_traj(base_dir, output_dir, view=\"wrist\")  # front/top/wrist 중 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_0_wrist.npz: img (97, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_10_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_11_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_12_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_13_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_14_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_15_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_16_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_17_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_18_wrist.npz: img (100, 16), state (100, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_19_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_1_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_20_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_21_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_22_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_23_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_24_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_25_wrist.npz: img (102, 16), state (102, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_26_wrist.npz: img (101, 16), state (101, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_27_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_28_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_29_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_2_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_30_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_31_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_32_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_33_wrist.npz: img (103, 16), state (103, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_34_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_35_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_36_wrist.npz: img (100, 16), state (100, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_37_wrist.npz: img (105, 16), state (105, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_38_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_39_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_3_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_40_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_41_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_42_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_43_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_44_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_45_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_46_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_47_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_48_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_49_wrist.npz: img (102, 16), state (102, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_4_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_50_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_52_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_53_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_54_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_55_wrist.npz: img (104, 16), state (104, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_56_wrist.npz: img (101, 16), state (101, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_57_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_58_wrist.npz: img (102, 16), state (102, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_59_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_5_wrist.npz: img (100, 16), state (100, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_60_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_61_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_62_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_63_wrist.npz: img (100, 16), state (100, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_64_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_65_wrist.npz: img (100, 16), state (100, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_66_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_67_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_68_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_69_wrist.npz: img (93, 16), state (93, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_6_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_70_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_71_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_73_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_74_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_75_wrist.npz: img (101, 16), state (101, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_76_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_77_wrist.npz: img (100, 16), state (100, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_78_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_79_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_7_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_80_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_81_wrist.npz: img (101, 16), state (101, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_82_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_83_wrist.npz: img (101, 16), state (101, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_84_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_85_wrist.npz: img (96, 16), state (96, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_86_wrist.npz: img (94, 16), state (94, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_87_wrist.npz: img (93, 16), state (93, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_88_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_89_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_8_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_90_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_91_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_92_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_93_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_94_wrist.npz: img (104, 16), state (104, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_95_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_96_wrist.npz: img (95, 16), state (95, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_97_wrist.npz: img (99, 16), state (99, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_98_wrist.npz: img (97, 16), state (97, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_99_wrist.npz: img (98, 16), state (98, 9)\n",
      "[Saved] /AILAB-summer-school-2025/success_traj_comp/success_traj_9_wrist.npz: img (98, 16), state (98, 9)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Key: img\n",
    "#   Shape: (97, 16)\n",
    "#   Dtype: float32\n",
    "#   Sample (first element):\n",
    "# [-0.5854379   1.6493505  -1.0049931  -0.21947424 -0.70256466 -0.39046937\n",
    "#  -0.4245706  -0.36956656  0.24001157 -0.14053325]\n",
    "# ------------------------------------------------------------\n",
    "# Key: robot_state\n",
    "#   Shape: (97, 9)\n",
    "#   Dtype: float32\n",
    "#   Sample (first element):\n",
    "# [ 4.6333355e-01  5.1339157e-08  3.8548785e-01  8.6034834e-03\n",
    "#   9.2161107e-01  2.0462854e-02  3.8747975e-01 -3.5621226e-05\n",
    "#   0.0000000e+00  3.0250198e-01]\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ----- Image feature extractor -----\n",
    "def get_image_feature(image_path, model, transform, device=\"cpu\"):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.squeeze().cpu().numpy()\n",
    "\n",
    "# ----- Main processing function -----\n",
    "def process_success_traj(base_dir, output_dir, view=\"top\"):\n",
    "    \"\"\"\n",
    "    base_dir: success_traj root directory (/AILAB-summer-school-2025/success_traj/)\n",
    "    output_dir: where to save merged dicts\n",
    "    view: \"front\", \"top\", or \"wrist\"\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Pretrained ResNet18 -> 16D feature\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    num_ftrs = resnet18.fc.in_features\n",
    "    resnet18.fc = nn.Linear(num_ftrs, 16)\n",
    "    resnet18 = resnet18.to(device)\n",
    "    resnet18.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Traverse all traj folders\n",
    "    for traj_folder in sorted(os.listdir(base_dir)):\n",
    "        traj_path = os.path.join(base_dir, traj_folder)\n",
    "        if not os.path.isdir(traj_path) or not traj_folder.startswith(\"simulation_traj_\"):\n",
    "            continue\n",
    "\n",
    "        traj_num = traj_folder.split(\"_\")[2]\n",
    "        dict_name = f\"success_traj_{traj_num}_{view}\"\n",
    "\n",
    "        # Collect image features\n",
    "        img_features = []\n",
    "        for filename in sorted(os.listdir(traj_path)):\n",
    "            if filename.startswith(f\"{view}_view\") and filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(traj_path, filename)\n",
    "                feat = get_image_feature(image_path, resnet18, transform, device)\n",
    "                img_features.append(feat)\n",
    "\n",
    "        img_features = np.stack(img_features, axis=0)  # shape: [num_images, feature_dim]\n",
    "\n",
    "        # Collect robot states from all timestep npz\n",
    "        all_states = []\n",
    "        for file in sorted(os.listdir(traj_path)):\n",
    "            if file.endswith(\".npz\") and file.startswith(\"states_\"):\n",
    "                file_path = os.path.join(traj_path, file)\n",
    "                data = np.load(file_path)\n",
    "                for key in data.files:\n",
    "                    all_states.append(data[key])\n",
    "\n",
    "        robot_states = np.concatenate(all_states, axis=0)\n",
    "\n",
    "        # Build dict\n",
    "        traj_dict = {\n",
    "            \"img\": img_features,\n",
    "            \"robot_state\": robot_states\n",
    "        }\n",
    "\n",
    "        # Save npz\n",
    "        save_path = os.path.join(output_dir, f\"{dict_name}.npz\")\n",
    "        np.savez(save_path, **traj_dict)\n",
    "\n",
    "        print(f\"[Saved] {save_path}: img {img_features.shape}, state {robot_states.shape}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/AILAB-summer-school-2025/success_traj/\"\n",
    "    output_dir = \"/AILAB-summer-school-2025/success_traj_comp/\"\n",
    "    process_success_traj(base_dir, output_dir, view=\"wrist\")  # front/top/wrist 중 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting /AILAB-summer-school-2025/success_traj/success_traj_comp_front/success_traj_2_front.npz\n",
      "------------------------------------------------------------\n",
      "Key: img\n",
      "  Shape: (97, 16)\n",
      "  Dtype: float32\n",
      "  Sample (first element):\n",
      "[-0.5854379   1.6493505  -1.0049931  -0.21947424 -0.70256466 -0.39046937\n",
      " -0.4245706  -0.36956656  0.24001157 -0.14053325]\n",
      "------------------------------------------------------------\n",
      "Key: robot_state\n",
      "  Shape: (97, 9)\n",
      "  Dtype: float32\n",
      "  Sample (first element):\n",
      "[ 4.6333355e-01  5.1339157e-08  3.8548785e-01  8.6034834e-03\n",
      "  9.2161107e-01  2.0462854e-02  3.8747975e-01 -3.5621226e-05\n",
      "  0.0000000e+00  3.0250198e-01]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_npz(file_path):\n",
    "    \"\"\"\n",
    "    Inspect contents of a .npz file: keys, shapes, and dtypes\n",
    "    \"\"\"\n",
    "    data = np.load(file_path)\n",
    "    print(f\"Inspecting {file_path}\")\n",
    "    print(\"-\" * 60)\n",
    "    for key in data.files:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"  Shape: {data[key].shape}\")\n",
    "        print(f\"  Dtype: {data[key].dtype}\")\n",
    "        print(f\"  Sample (first element):\\n{data[key].flatten()[:10]}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"/AILAB-summer-school-2025/success_traj/success_traj_comp_front/success_traj_2_front.npz\"\n",
    "    inspect_npz(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-Only Processor Config\n",
      "Views: ['front', 'top', 'wrist']\n",
      "ResNet Features: 512 per view\n",
      "Compressed Features: 64 per view\n",
      "Total Compressed: 192\n",
      "Device: cuda\n",
      "============================================================\n",
      "Image-Only Processing Pipeline\n",
      "Extracting latent vectors from multiview images\n",
      "============================================================\n",
      "ResNet18 feature extractor initialized\n",
      "\n",
      "1. Building image index...\n",
      "Building image index from: success_traj_img\n",
      "Total images: 0, Parsed: 0, Complete triplets: 0\n",
      "\n",
      " Processing failed: No complete image triplets found!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No complete image triplets found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 335\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    334\u001b[0m     config \u001b[38;5;241m=\u001b[39m ImageOnlyConfig()\n\u001b[0;32m--> 335\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_images_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImage latent vectors ready: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 331\u001b[0m, in \u001b[0;36mprocess_images_only\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Processing failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[8], line 302\u001b[0m, in \u001b[0;36mprocess_images_only\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    299\u001b[0m complete_count \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mbuild_image_index()\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complete_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo complete image triplets found!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Step 2: Extract raw features\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. Extracting ResNet18 features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No complete image triplets found!"
     ]
    }
   ],
   "source": [
    "# success case \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "@dataclass\n",
    "class ImageOnlyConfig:\n",
    "    \"\"\"Configuration for image-only processing\"\"\"\n",
    "    \n",
    "    # ===== PATHS =====\n",
    "    IMAGE_FOLDER: str = \"success_traj_img\"\n",
    "    \n",
    "    OUTPUT_PATH: str = \"image_features.npz\"\n",
    "    PCA_MODEL_PATH: str = \"image_pca_models.pkl\"\n",
    "    \n",
    "    # ===== IMAGE PROCESSING =====\n",
    "    RESNET_FEATURE_DIM: int = 512  # ResNet18 final layer per view\n",
    "    VIEWS: List[str] = None\n",
    "    \n",
    "    # ===== PCA COMPRESSION =====\n",
    "    COMPRESSED_DIM: int = 64  # Final compressed dimension per view\n",
    "    TOTAL_COMPRESSED_DIM: int = 192  # 64 * 3 views\n",
    "    \n",
    "    # ===== MODEL =====\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE: int = 32\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.VIEWS is None:\n",
    "            self.VIEWS = [\"front\", \"top\", \"wrist\"]\n",
    "        \n",
    "        print(f\"Image-Only Processor Config\")\n",
    "        print(f\"Views: {self.VIEWS}\")\n",
    "        print(f\"ResNet Features: {self.RESNET_FEATURE_DIM} per view\")\n",
    "        print(f\"Compressed Features: {self.COMPRESSED_DIM} per view\")\n",
    "        print(f\"Total Compressed: {self.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"Device: {self.DEVICE}\")\n",
    "\n",
    "class ImageOnlyProcessor:\n",
    "    \"\"\"Process only images to create latent vectors\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ImageOnlyConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.DEVICE)\n",
    "\n",
    "        # Initialize ResNet18\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])  # Remove classifier\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Image preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Storage\n",
    "        self.image_index = {}\n",
    "        self.pca_models = {}\n",
    "        \n",
    "        print(f\"ResNet18 feature extractor initialized\")\n",
    "    \n",
    "    def parse_filename(self, filename: str) -> Optional[Tuple[str, str, int]]:\n",
    "        \"\"\"Parse image filename: traj_key, view, timestep\"\"\"\n",
    "        name = filename.replace('.png', '')\n",
    "        parts = name.split('_')\n",
    "        \n",
    "        try:\n",
    "            # Find view\n",
    "            view = None\n",
    "            view_idx = -1\n",
    "            for i, part in enumerate(parts):\n",
    "                if part in self.config.VIEWS:\n",
    "                    view = part\n",
    "                    view_idx = i\n",
    "                    break\n",
    "            \n",
    "            if view is None:\n",
    "                return None\n",
    "            \n",
    "            # Extract trajectory key and timestep\n",
    "            traj_key = '_'.join(parts[:view_idx])\n",
    "            timestep = int(parts[-1])\n",
    "            \n",
    "            return traj_key, view, timestep\n",
    "            \n",
    "        except (ValueError, IndexError):\n",
    "            return None\n",
    "    \n",
    "    def build_image_index(self):\n",
    "        print(f\"Building image index from: {self.config.IMAGE_FOLDER}\")\n",
    "        image_index = defaultdict(lambda: defaultdict(dict))\n",
    "        total_images, parsed_images = 0, 0\n",
    "\n",
    "        for root, _, files in os.walk(self.config.IMAGE_FOLDER):\n",
    "            for filename in files:\n",
    "                if not filename.endswith('.png'):\n",
    "                    continue\n",
    "                total_images += 1\n",
    "                parse_result = self.parse_filename(filename)\n",
    "                if parse_result:\n",
    "                    traj_key, view, timestep = parse_result\n",
    "                    image_path = os.path.join(root, filename)\n",
    "                    image_index[traj_key][timestep][view] = image_path\n",
    "                    parsed_images += 1\n",
    "\n",
    "        complete_triplets = sum(\n",
    "            len(image_index[traj][ts]) == len(self.config.VIEWS)\n",
    "            for traj in image_index for ts in image_index[traj]\n",
    "        )\n",
    "\n",
    "        print(f\"Total images: {total_images}, Parsed: {parsed_images}, Complete triplets: {complete_triplets}\")\n",
    "        self.image_index = dict(image_index)\n",
    "        return complete_triplets\n",
    "    \n",
    "    def extract_features(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Extract ResNet18 features from single image\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = self.model(image_tensor)\n",
    "                features = features.view(features.size(0), -1)\n",
    "            \n",
    "            return features.cpu().numpy().flatten()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return np.zeros(self.config.RESNET_FEATURE_DIM)\n",
    "    \n",
    "    def extract_all_image_features(self) -> Dict[str, Dict[int, np.ndarray]]:\n",
    "        \"\"\"Extract features for all complete image triplets\"\"\"\n",
    "        print(\"Extracting multiview image features...\")\n",
    "        \n",
    "        features_dict = {}\n",
    "        total_processed = 0\n",
    "        \n",
    "        for traj_key in tqdm(self.image_index, desc=\"Processing trajectories\"):\n",
    "            features_dict[traj_key] = {}\n",
    "            \n",
    "            for timestep in self.image_index[traj_key]:\n",
    "                # Check if all views available\n",
    "                available_views = set(self.image_index[traj_key][timestep].keys())\n",
    "                required_views = set(self.config.VIEWS)\n",
    "                \n",
    "                if available_views == required_views:\n",
    "                    # Extract features from all 3 views\n",
    "                    view_features = []\n",
    "                    \n",
    "                    for view in self.config.VIEWS:\n",
    "                        image_path = self.image_index[traj_key][timestep][view]\n",
    "                        features = self.extract_features(image_path)\n",
    "                        view_features.append(features)\n",
    "                    \n",
    "                    # Concatenate all view features\n",
    "                    combined_features = np.concatenate(view_features)  # [1536,]\n",
    "                    features_dict[traj_key][timestep] = combined_features\n",
    "                    total_processed += 1\n",
    "        \n",
    "        print(f\"Extracted features for {total_processed} complete image triplets\")\n",
    "        return features_dict\n",
    "    \n",
    "    def fit_pca_models(self, features_dict: Dict) -> Dict[str, PCA]:\n",
    "        \"\"\"Fit PCA for each view separately\"\"\"\n",
    "        print(\"Fitting PCA compression models...\")\n",
    "        \n",
    "        # Collect features by view\n",
    "        view_features = {view: [] for view in self.config.VIEWS}\n",
    "        \n",
    "        for traj_key in features_dict:\n",
    "            for timestep in features_dict[traj_key]:\n",
    "                combined_features = features_dict[traj_key][timestep]\n",
    "                \n",
    "                # Split by view\n",
    "                for i, view in enumerate(self.config.VIEWS):\n",
    "                    start_idx = i * self.config.RESNET_FEATURE_DIM\n",
    "                    end_idx = (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                    view_feature = combined_features[start_idx:end_idx]\n",
    "                    view_features[view].append(view_feature)\n",
    "        \n",
    "        # Fit PCA for each view\n",
    "        pca_models = {}\n",
    "        for view in self.config.VIEWS:\n",
    "            if view_features[view]:\n",
    "                features_array = np.array(view_features[view])\n",
    "                \n",
    "                pca = PCA(n_components=self.config.COMPRESSED_DIM)\n",
    "                pca.fit(features_array)\n",
    "                \n",
    "                explained_var = pca.explained_variance_ratio_.sum()\n",
    "                print(f\"  {view} view: {explained_var:.3f} variance explained\")\n",
    "                \n",
    "                pca_models[view] = pca\n",
    "        \n",
    "        self.pca_models = pca_models\n",
    "        return pca_models\n",
    "    \n",
    "    def compress_all_features(self, features_dict: Dict) -> Dict[str, Dict[int, np.ndarray]]:\n",
    "        \"\"\"Apply PCA compression to all features\"\"\"\n",
    "        print(\"Compressing features with PCA...\")\n",
    "        \n",
    "        compressed_dict = {}\n",
    "        \n",
    "        for traj_key in tqdm(features_dict, desc=\"Compressing\"):\n",
    "            compressed_dict[traj_key] = {}\n",
    "            \n",
    "            for timestep in features_dict[traj_key]:\n",
    "                combined_features = features_dict[traj_key][timestep]\n",
    "                \n",
    "                # Compress each view separately\n",
    "                compressed_views = []\n",
    "                for i, view in enumerate(self.config.VIEWS):\n",
    "                    start_idx = i * self.config.RESNET_FEATURE_DIM\n",
    "                    end_idx = (i + 1) * self.config.RESNET_FEATURE_DIM\n",
    "                    view_feature = combined_features[start_idx:end_idx]\n",
    "                    \n",
    "                    if view in self.pca_models:\n",
    "                        compressed_feature = self.pca_models[view].transform([view_feature])\n",
    "                        compressed_views.append(compressed_feature.flatten())\n",
    "                    else:\n",
    "                        compressed_views.append(np.zeros(self.config.COMPRESSED_DIM))\n",
    "                \n",
    "                # Combine compressed features from all views\n",
    "                final_compressed = np.concatenate(compressed_views)  # [192,]\n",
    "                compressed_dict[traj_key][timestep] = final_compressed\n",
    "        \n",
    "        return compressed_dict\n",
    "    \n",
    "    def save_image_features(self, compressed_features: Dict):\n",
    "        \"\"\"Save image features only\"\"\"\n",
    "        print(f\"Saving image features to: {self.config.OUTPUT_PATH}\")\n",
    "        \n",
    "        # Convert to arrays with metadata\n",
    "        feature_list = []\n",
    "        metadata_list = []\n",
    "        \n",
    "        for traj_key in compressed_features:\n",
    "            for timestep in compressed_features[traj_key]:\n",
    "                feature_vector = compressed_features[traj_key][timestep]\n",
    "                feature_list.append(feature_vector)\n",
    "                \n",
    "                metadata_list.append({\n",
    "                    'traj_key': traj_key,\n",
    "                    'timestep': timestep,\n",
    "                    'feature_dim': len(feature_vector)\n",
    "                })\n",
    "        \n",
    "        feature_array = np.array(feature_list)\n",
    "        \n",
    "        # Save features\n",
    "        np.savez_compressed(\n",
    "            self.config.OUTPUT_PATH,\n",
    "            features=feature_array,\n",
    "            metadata=metadata_list,\n",
    "            config=self.config.__dict__\n",
    "        )\n",
    "        \n",
    "        # Save PCA models\n",
    "        with open(self.config.PCA_MODEL_PATH, 'wb') as f:\n",
    "            pickle.dump(self.pca_models, f)\n",
    "        \n",
    "        print(f\"Image features saved:\")\n",
    "        print(f\"  Features: {self.config.OUTPUT_PATH}\")\n",
    "        print(f\"  PCA models: {self.config.PCA_MODEL_PATH}\")\n",
    "        print(f\"  Total features: {len(feature_array)}\")\n",
    "        print(f\"  Feature dimension: {feature_array.shape[1]}\")\n",
    "        print(f\"  File size: {os.path.getsize(self.config.OUTPUT_PATH)/1024/1024:.1f} MB\")\n",
    "\n",
    "def process_images_only(config: ImageOnlyConfig = None) -> str:\n",
    "    \"\"\"\n",
    "    Main function to process images only\n",
    "    \n",
    "    Returns:\n",
    "        Path to generated image features file\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = ImageOnlyConfig()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Image-Only Processing Pipeline\")\n",
    "    print(\"Extracting latent vectors from multiview images\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Initialize processor\n",
    "        processor = ImageOnlyProcessor(config)\n",
    "        \n",
    "        # Step 1: Build image index\n",
    "        print(\"\\n1. Building image index...\")\n",
    "        complete_count = processor.build_image_index()\n",
    "        \n",
    "        if complete_count == 0:\n",
    "            raise ValueError(\"No complete image triplets found!\")\n",
    "        \n",
    "        # Step 2: Extract raw features\n",
    "        print(\"\\n2. Extracting ResNet18 features...\")\n",
    "        features_dict = processor.extract_all_image_features()\n",
    "        \n",
    "        # Step 3: Fit PCA\n",
    "        print(\"\\n3. Fitting PCA compression...\")\n",
    "        processor.fit_pca_models(features_dict)\n",
    "        \n",
    "        # Step 4: Compress features\n",
    "        print(\"\\n4. Compressing features...\")\n",
    "        compressed_features = processor.compress_all_features(features_dict)\n",
    "        \n",
    "        # Step 5: Save results\n",
    "        print(\"\\n5. Saving image features...\")\n",
    "        processor.save_image_features(compressed_features)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Image-Only Processing Completed Successfully!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"✅ Generated: {config.OUTPUT_PATH}\")\n",
    "        print(f\"✅ Feature dimension: {config.TOTAL_COMPRESSED_DIM}\")\n",
    "        print(f\"✅ Views processed: {config.VIEWS}\")\n",
    "        \n",
    "        return config.OUTPUT_PATH\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Processing failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = ImageOnlyConfig()\n",
    "    output_path = process_images_only(config)\n",
    "    print(f\"\\nImage latent vectors ready: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ResNet18 for multiview\n",
      "\n",
      "Processing /AILAB-summer-school-2025/failure_case/failcase2/simulation_traj_0_20250729_071723_len700_failure(outOfControl_pregrasp)\n",
      "  Fitting PCA models...\n",
      "  PCA fitted for front: explains 0.988\n",
      "  PCA fitted for top: explains 0.990\n",
      "  PCA fitted for wrist: explains 0.996\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      "  저장 완료: 139 timesteps, feature dim 192\n",
      "Image features saved:\n",
      "  Features: /AILAB-summer-school-2025/failure_case_comp/failcase2/simulation_traj_0_20250729_071723_len700_failure(outOfControl_pregrasp)/img/features.pkl\n",
      "  Total timesteps: 139\n",
      "  Feature dimension: 192\n",
      "\n",
      "Processing /AILAB-summer-school-2025/failure_case/failcase2/simulation_traj_4_20250729_072133_len700_failure(outOfControl_pregrasp)\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      "  저장 완료: 140 timesteps, feature dim 192\n",
      "Image features saved:\n",
      "  Features: /AILAB-summer-school-2025/failure_case_comp/failcase2/simulation_traj_4_20250729_072133_len700_failure(outOfControl_pregrasp)/img/features.pkl\n",
      "  Total timesteps: 140\n",
      "  Feature dimension: 192\n",
      "\n",
      "Processing /AILAB-summer-school-2025/failure_case/failcase2/simulation_traj_1_20250729_071825_len700_failure(outOfControl_pregrasp)\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      "  저장 완료: 140 timesteps, feature dim 192\n",
      "Image features saved:\n",
      "  Features: /AILAB-summer-school-2025/failure_case_comp/failcase2/simulation_traj_1_20250729_071825_len700_failure(outOfControl_pregrasp)/img/features.pkl\n",
      "  Total timesteps: 140\n",
      "  Feature dimension: 192\n",
      "\n",
      "Processing /AILAB-summer-school-2025/failure_case/failcase2/simulation_traj_3_20250729_072030_len700_failure(outOfControl_pregrasp)\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      "  저장 완료: 140 timesteps, feature dim 192\n",
      "Image features saved:\n",
      "  Features: /AILAB-summer-school-2025/failure_case_comp/failcase2/simulation_traj_3_20250729_072030_len700_failure(outOfControl_pregrasp)/img/features.pkl\n",
      "  Total timesteps: 140\n",
      "  Feature dimension: 192\n",
      "\n",
      "Processing /AILAB-summer-school-2025/failure_case/failcase2/simulation_traj_2_20250729_071926_len700_failure(outOfControl_pregrasp)\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      " keys=['robot_state'], shapes={'robot_state': (1, 9)}\n",
      "  저장 완료: 140 timesteps, feature dim 192\n",
      "Image features saved:\n",
      "  Features: /AILAB-summer-school-2025/failure_case_comp/failcase2/simulation_traj_2_20250729_071926_len700_failure(outOfControl_pregrasp)/img/features.pkl\n",
      "  Total timesteps: 140\n",
      "  Feature dimension: 192\n"
     ]
    }
   ],
   "source": [
    "# failure case\n",
    "\n",
    "import os, pickle, numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "\n",
    "class MultiViewConfig:\n",
    "    IMAGE_ROOT: str = \"/AILAB-summer-school-2025/failure_case/failcase2\"\n",
    "    OUTPUT_ROOT: str = \"/AILAB-summer-school-2025/failure_case_comp/failcase2\"\n",
    "    VIEWS: dict = {\"front_view\": \"front\", \"top_view\": \"top\", \"wrist_view\": \"wrist\"}\n",
    "    RESNET_FEATURE_DIM: int = 512\n",
    "    COMPRESSED_DIM: int = 64\n",
    "    TOTAL_COMPRESSED_DIM: int = 64 * 3\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class MultiViewProcessor:\n",
    "    def __init__(self, config: MultiViewConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.DEVICE)\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        self.model.to(self.device).eval()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                 std=[0.229,0.224,0.225])\n",
    "        ])\n",
    "        self.pca_models = {}\n",
    "        print(\"Initialized ResNet18 for multiview\")\n",
    "\n",
    "    def extract_feature(self, image_path: str) -> np.ndarray:\n",
    "        try:\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "            x = self.transform(img).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                feat = self.model(x).view(1,-1)\n",
    "            return feat.cpu().numpy().flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return np.zeros(self.config.RESNET_FEATURE_DIM)\n",
    "\n",
    "    def parse_filename(self, filename: str):\n",
    "        if not filename.endswith(\".png\"):\n",
    "            return None\n",
    "        name = filename.replace(\".png\", \"\")\n",
    "        # view 매칭\n",
    "        view = None\n",
    "        for candidate in [\"front_view\", \"top_view\", \"wrist_view\"]:\n",
    "            if candidate in name:\n",
    "                view = candidate.replace(\"_view\", \"\")\n",
    "                break\n",
    "        if view is None:\n",
    "            return None\n",
    "        try:\n",
    "            timestep = int(name.split(\"_\")[-1])\n",
    "        except ValueError:\n",
    "            return None\n",
    "        traj_key = name.rsplit(f\"_{view}_\", 1)[0]\n",
    "        return traj_key, view, timestep\n",
    "\n",
    "    def fit_pca_models(self, feats: np.ndarray):\n",
    "        \"\"\"fit PCA per view from stacked feats\"\"\"\n",
    "        pca_models, reduced_views = {}, []\n",
    "        for i, view in enumerate([\"front\",\"top\",\"wrist\"]):\n",
    "            view_data = feats[:, i*512:(i+1)*512]\n",
    "            pca = PCA(n_components=self.config.COMPRESSED_DIM)\n",
    "            pca.fit(view_data)\n",
    "            explained = pca.explained_variance_ratio_.sum()\n",
    "            print(f\"  PCA fitted for {view}: explains {explained:.3f}\")\n",
    "            pca_models[view] = pca\n",
    "        self.pca_models = pca_models\n",
    "        return pca_models\n",
    "\n",
    "    def process_traj(self, traj_dir):\n",
    "        print(f\"\\nProcessing {traj_dir}\")\n",
    "\n",
    "        traj_name = os.path.basename(traj_dir)\n",
    "        # output trajectory dir\n",
    "        out_traj_dir = os.path.join(self.config.OUTPUT_ROOT, traj_name)\n",
    "        img_out = os.path.join(out_traj_dir, \"img\")\n",
    "        state_out = os.path.join(out_traj_dir, \"robot_state\")\n",
    "        os.makedirs(img_out, exist_ok=True)\n",
    "        os.makedirs(state_out, exist_ok=True)\n",
    "\n",
    "        image_index = defaultdict(dict)\n",
    "        for fname in os.listdir(traj_dir):\n",
    "            res = self.parse_filename(fname)\n",
    "            if res:\n",
    "                traj_key, view, ts = res\n",
    "                image_index[ts][view] = os.path.join(traj_dir, fname)\n",
    "\n",
    "        timesteps = [t for t in image_index if len(image_index[t]) == 3]\n",
    "        if not timesteps:\n",
    "            print(\"  No complete triplets found\")\n",
    "            return\n",
    "        timesteps = sorted(timesteps)\n",
    "\n",
    "        # 이미지 feature 추출\n",
    "        feats = []\n",
    "        for t in timesteps:\n",
    "            view_feats = []\n",
    "            for view in [\"front\",\"top\",\"wrist\"]:\n",
    "                feat = self.extract_feature(image_index[t][view])\n",
    "                view_feats.append(feat)\n",
    "            feats.append(np.concatenate(view_feats))\n",
    "        feats = np.array(feats)\n",
    "\n",
    "        # PCA transform (fit if first traj)\n",
    "        if not self.pca_models:\n",
    "            print(\"  Fitting PCA models...\")\n",
    "            self.fit_pca_models(feats)\n",
    "\n",
    "        reduced_views = []\n",
    "        for i, view in enumerate([\"front\",\"top\",\"wrist\"]):\n",
    "            view_data = feats[:, i*512:(i+1)*512]\n",
    "            reduced = self.pca_models[view].transform(view_data)\n",
    "            reduced_views.append(reduced)\n",
    "        final_feats = np.concatenate(reduced_views, axis=1)\n",
    "\n",
    "        feat_dict = {t: final_feats[i] for i,t in enumerate(timesteps)}\n",
    "\n",
    "        # state npz 합치기\n",
    "        state_dict = {}\n",
    "        for fname in os.listdir(traj_dir):\n",
    "            if fname.endswith(\".npz\") and (fname.startswith(\"state_\") or fname.startswith(\"states_\")):\n",
    "                npz_path = os.path.join(traj_dir,fname)\n",
    "                try:\n",
    "                    ts = int(fname.split(\"_\")[-1].replace(\".npz\",\"\"))\n",
    "                except ValueError:\n",
    "                    print(f\"  ⚠️ Cannot parse timestep from {fname}\")\n",
    "                    continue\n",
    "\n",
    "                data = np.load(npz_path)\n",
    "                state_dict[ts] = {k: data[k] for k in data}\n",
    "\n",
    "        # 저장\n",
    "        with open(os.path.join(img_out,\"features.pkl\"),\"wb\") as f:\n",
    "            pickle.dump(feat_dict,f)\n",
    "\n",
    "        if state_dict:\n",
    "            np.savez_compressed(os.path.join(state_out,\"state.npz\"),\n",
    "                                **{f\"t{t}\": state_dict[t] for t in timesteps})\n",
    "        else:\n",
    "            print(\"  ⚠️ No robot state npz files found for this trajectory.\")\n",
    "\n",
    "        feature_array = np.array(list(feat_dict.values()))\n",
    "        print(f\"  저장 완료: {len(feature_array)} timesteps, feature dim {feature_array.shape[1]}\")\n",
    "\n",
    "        print(f\"Image features saved:\")\n",
    "        print(f\"  Features: {img_out}/features.pkl\")\n",
    "        print(f\"  Total timesteps: {len(feature_array)}\")\n",
    "        print(f\"  Feature dimension: {feature_array.shape[1]}\")\n",
    "\n",
    "def process_all(root_dir):\n",
    "    config = MultiViewConfig()\n",
    "    proc = MultiViewProcessor(config)\n",
    "    for traj in os.listdir(root_dir):\n",
    "        traj_dir = os.path.join(root_dir,traj)\n",
    "        if os.path.isdir(traj_dir):\n",
    "            proc.process_traj(traj_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all(\"/AILAB-summer-school-2025/failure_case/failcase2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
